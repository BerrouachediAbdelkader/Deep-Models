{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GLCM_pan</th>\n",
       "      <th>Mean_Green</th>\n",
       "      <th>Mean_Red</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>SD_pan</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656711</td>\n",
       "      <td>0.050984</td>\n",
       "      <td>0.044570</td>\n",
       "      <td>0.218476</td>\n",
       "      <td>0.132110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.680591</td>\n",
       "      <td>0.049425</td>\n",
       "      <td>0.041939</td>\n",
       "      <td>0.177275</td>\n",
       "      <td>0.106749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.734892</td>\n",
       "      <td>0.047396</td>\n",
       "      <td>0.042926</td>\n",
       "      <td>0.259034</td>\n",
       "      <td>0.143741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698087</td>\n",
       "      <td>0.035317</td>\n",
       "      <td>0.027066</td>\n",
       "      <td>0.127065</td>\n",
       "      <td>0.095697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.738927</td>\n",
       "      <td>0.046076</td>\n",
       "      <td>0.040228</td>\n",
       "      <td>0.295501</td>\n",
       "      <td>0.112481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GLCM_pan  Mean_Green  Mean_Red  Mean_NIR    SD_pan  outlier\n",
       "0  0.656711    0.050984  0.044570  0.218476  0.132110        1\n",
       "1  0.680591    0.049425  0.041939  0.177275  0.106749        1\n",
       "2  0.734892    0.047396  0.042926  0.259034  0.143741        1\n",
       "3  0.698087    0.035317  0.027066  0.127065  0.095697        1\n",
       "4  0.738927    0.046076  0.040228  0.295501  0.112481        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('Wilt_withoutdupl_norm_05.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/Wilt.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,5]\n",
    "X = df[:,0:5]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:44:16,855][cascade_classifier.fit_transform] X_groups_train.shape=[(3373, 5)],y_train.shape=(3373,),X_groups_test.shape=[(1446, 5)],y_test.shape=(1446,)\n",
      "[ 2018-04-25 20:44:16,857][cascade_classifier.fit_transform] group_dims=[5]\n",
      "[ 2018-04-25 20:44:16,858][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-04-25 20:44:16,860][cascade_classifier.fit_transform] group_ends=[5]\n",
      "[ 2018-04-25 20:44:16,861][cascade_classifier.fit_transform] X_train.shape=(3373, 5),X_test.shape=(1446, 5)\n",
      "[ 2018-04-25 20:44:16,863][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(3373, 5), X_cur_test.shape=(1446, 5)\n",
      "[ 2018-04-25 20:44:17,499][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=98.82%\n",
      "[ 2018-04-25 20:44:18,293][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=98.52%\n",
      "[ 2018-04-25 20:44:19,095][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=98.22%\n",
      "[ 2018-04-25 20:44:19,876][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=98.82%\n",
      "[ 2018-04-25 20:44:20,666][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=98.22%\n",
      "[ 2018-04-25 20:44:21,463][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-04-25 20:44:22,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=97.92%\n",
      "[ 2018-04-25 20:44:23,160][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=99.40%\n",
      "[ 2018-04-25 20:44:23,954][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=97.02%\n",
      "[ 2018-04-25 20:44:24,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=98.81%\n",
      "[ 2018-04-25 20:44:24,897][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=98.37%\n",
      "[ 2018-04-25 20:44:24,899][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.23%\n",
      "[ 2018-04-25 20:44:25,514][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=98.52%\n",
      "[ 2018-04-25 20:44:26,312][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=98.52%\n",
      "[ 2018-04-25 20:44:27,101][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=98.22%\n",
      "[ 2018-04-25 20:44:27,878][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-04-25 20:44:28,690][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=97.63%\n",
      "[ 2018-04-25 20:44:29,455][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=97.93%\n",
      "[ 2018-04-25 20:44:30,327][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=98.52%\n",
      "[ 2018-04-25 20:44:31,103][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=98.51%\n",
      "[ 2018-04-25 20:44:31,937][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=98.21%\n",
      "[ 2018-04-25 20:44:32,699][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=98.81%\n",
      "[ 2018-04-25 20:44:32,853][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=98.28%\n",
      "[ 2018-04-25 20:44:32,855][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=97.44%\n",
      "[ 2018-04-25 20:44:32,921][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=94.67%\n",
      "[ 2018-04-25 20:44:32,936][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=94.67%\n",
      "[ 2018-04-25 20:44:32,947][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=94.67%\n",
      "[ 2018-04-25 20:44:32,959][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=94.67%\n",
      "[ 2018-04-25 20:44:32,969][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=94.67%\n",
      "[ 2018-04-25 20:44:32,979][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=94.67%\n",
      "[ 2018-04-25 20:44:32,993][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=94.96%\n",
      "[ 2018-04-25 20:44:33,006][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=94.94%\n",
      "[ 2018-04-25 20:44:33,017][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=94.94%\n",
      "[ 2018-04-25 20:44:33,029][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=94.94%\n",
      "[ 2018-04-25 20:44:33,031][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=94.78%\n",
      "[ 2018-04-25 20:44:33,033][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=94.40%\n",
      "[ 2018-04-25 20:44:33,034][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=97.27%\n",
      "[ 2018-04-25 20:44:33,036][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=96.54%\n",
      "[ 2018-04-25 20:44:33,038][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:44:33,705][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=97.34%\n",
      "[ 2018-04-25 20:44:34,497][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=100.00%\n",
      "[ 2018-04-25 20:44:35,277][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=98.22%\n",
      "[ 2018-04-25 20:44:36,276][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=99.70%\n",
      "[ 2018-04-25 20:44:37,103][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=99.11%\n",
      "[ 2018-04-25 20:44:37,913][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=99.41%\n",
      "[ 2018-04-25 20:44:38,683][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=99.41%\n",
      "[ 2018-04-25 20:44:39,486][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-04-25 20:44:40,301][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=99.11%\n",
      "[ 2018-04-25 20:44:41,100][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=97.92%\n",
      "[ 2018-04-25 20:44:41,236][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=98.93%\n",
      "[ 2018-04-25 20:44:41,238][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=98.27%\n",
      "[ 2018-04-25 20:44:41,913][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=98.82%\n",
      "[ 2018-04-25 20:44:42,773][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=97.93%\n",
      "[ 2018-04-25 20:44:43,577][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=99.41%\n",
      "[ 2018-04-25 20:44:44,397][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=98.82%\n",
      "[ 2018-04-25 20:44:45,219][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=98.82%\n",
      "[ 2018-04-25 20:44:46,034][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=99.41%\n",
      "[ 2018-04-25 20:44:46,887][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=98.81%\n",
      "[ 2018-04-25 20:44:47,726][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-04-25 20:44:48,585][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=98.21%\n",
      "[ 2018-04-25 20:44:49,433][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=99.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:44:49,583][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=98.90%\n",
      "[ 2018-04-25 20:44:49,585][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=98.27%\n",
      "[ 2018-04-25 20:44:49,607][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=98.52%\n",
      "[ 2018-04-25 20:44:49,622][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=98.82%\n",
      "[ 2018-04-25 20:44:49,636][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=99.41%\n",
      "[ 2018-04-25 20:44:49,660][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-04-25 20:44:49,672][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:44:49,685][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=98.22%\n",
      "[ 2018-04-25 20:44:49,696][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=98.81%\n",
      "[ 2018-04-25 20:44:49,707][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=98.51%\n",
      "[ 2018-04-25 20:44:49,717][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=98.81%\n",
      "[ 2018-04-25 20:44:49,727][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=99.11%\n",
      "[ 2018-04-25 20:44:49,728][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=98.81%\n",
      "[ 2018-04-25 20:44:49,730][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=97.65%\n",
      "[ 2018-04-25 20:44:49,731][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=98.90%\n",
      "[ 2018-04-25 20:44:49,732][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=98.06%\n",
      "[ 2018-04-25 20:44:49,734][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:44:50,330][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=98.22%\n",
      "[ 2018-04-25 20:44:51,113][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=99.11%\n",
      "[ 2018-04-25 20:44:51,901][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-04-25 20:44:52,707][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=99.11%\n",
      "[ 2018-04-25 20:44:53,508][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=98.82%\n",
      "[ 2018-04-25 20:44:54,344][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=99.41%\n",
      "[ 2018-04-25 20:44:55,175][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=99.41%\n",
      "[ 2018-04-25 20:44:56,024][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=98.81%\n",
      "[ 2018-04-25 20:44:56,828][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=99.40%\n",
      "[ 2018-04-25 20:44:57,651][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=98.21%\n",
      "[ 2018-04-25 20:44:57,790][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=98.84%\n",
      "[ 2018-04-25 20:44:57,793][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-04-25 20:44:58,412][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=98.52%\n",
      "[ 2018-04-25 20:44:59,217][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=99.41%\n",
      "[ 2018-04-25 20:45:00,030][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=99.70%\n",
      "[ 2018-04-25 20:45:00,874][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=98.52%\n",
      "[ 2018-04-25 20:45:01,720][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=99.11%\n",
      "[ 2018-04-25 20:45:02,553][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=98.52%\n",
      "[ 2018-04-25 20:45:03,345][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=98.81%\n",
      "[ 2018-04-25 20:45:04,130][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=98.81%\n",
      "[ 2018-04-25 20:45:04,996][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=99.40%\n",
      "[ 2018-04-25 20:45:05,840][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=98.51%\n",
      "[ 2018-04-25 20:45:06,001][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=98.93%\n",
      "[ 2018-04-25 20:45:06,003][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=97.99%\n",
      "[ 2018-04-25 20:45:06,030][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=98.52%\n",
      "[ 2018-04-25 20:45:06,045][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=98.82%\n",
      "[ 2018-04-25 20:45:06,060][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=98.82%\n",
      "[ 2018-04-25 20:45:06,074][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=98.82%\n",
      "[ 2018-04-25 20:45:06,092][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=99.11%\n",
      "[ 2018-04-25 20:45:06,108][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=99.11%\n",
      "[ 2018-04-25 20:45:06,123][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=99.41%\n",
      "[ 2018-04-25 20:45:06,137][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=98.21%\n",
      "[ 2018-04-25 20:45:06,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=98.81%\n",
      "[ 2018-04-25 20:45:06,163][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=99.70%\n",
      "[ 2018-04-25 20:45:06,166][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=98.93%\n",
      "[ 2018-04-25 20:45:06,167][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-04-25 20:45:06,169][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=98.96%\n",
      "[ 2018-04-25 20:45:06,171][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=98.06%\n",
      "[ 2018-04-25 20:45:06,173][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:45:06,788][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=98.82%\n",
      "[ 2018-04-25 20:45:07,722][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=98.82%\n",
      "[ 2018-04-25 20:45:08,524][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=99.41%\n",
      "[ 2018-04-25 20:45:09,338][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=98.52%\n",
      "[ 2018-04-25 20:45:10,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=98.22%\n",
      "[ 2018-04-25 20:45:11,001][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=98.52%\n",
      "[ 2018-04-25 20:45:11,831][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=99.11%\n",
      "[ 2018-04-25 20:45:12,703][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=97.92%\n",
      "[ 2018-04-25 20:45:13,488][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=99.70%\n",
      "[ 2018-04-25 20:45:14,271][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=98.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:45:14,420][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=98.78%\n",
      "[ 2018-04-25 20:45:14,422][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=97.99%\n",
      "[ 2018-04-25 20:45:15,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=98.82%\n",
      "[ 2018-04-25 20:45:15,844][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=98.82%\n",
      "[ 2018-04-25 20:45:16,619][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=98.22%\n",
      "[ 2018-04-25 20:45:17,540][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=98.82%\n",
      "[ 2018-04-25 20:45:18,343][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=99.70%\n",
      "[ 2018-04-25 20:45:19,127][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=98.82%\n",
      "[ 2018-04-25 20:45:19,922][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=99.11%\n",
      "[ 2018-04-25 20:45:20,745][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-04-25 20:45:21,564][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=98.81%\n",
      "[ 2018-04-25 20:45:22,343][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=99.40%\n",
      "[ 2018-04-25 20:45:22,496][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=98.96%\n",
      "[ 2018-04-25 20:45:22,498][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-04-25 20:45:22,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=98.82%\n",
      "[ 2018-04-25 20:45:22,545][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=99.11%\n",
      "[ 2018-04-25 20:45:22,562][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=99.11%\n",
      "[ 2018-04-25 20:45:22,582][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=99.41%\n",
      "[ 2018-04-25 20:45:22,599][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-04-25 20:45:22,614][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=99.41%\n",
      "[ 2018-04-25 20:45:22,628][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=99.11%\n",
      "[ 2018-04-25 20:45:22,642][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-04-25 20:45:22,655][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=99.11%\n",
      "[ 2018-04-25 20:45:22,668][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=98.21%\n",
      "[ 2018-04-25 20:45:22,671][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=98.99%\n",
      "[ 2018-04-25 20:45:22,672][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=97.99%\n",
      "[ 2018-04-25 20:45:22,674][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=98.96%\n",
      "[ 2018-04-25 20:45:22,676][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=98.13%\n",
      "[ 2018-04-25 20:45:22,678][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:45:23,287][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=98.82%\n",
      "[ 2018-04-25 20:45:24,084][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=99.11%\n",
      "[ 2018-04-25 20:45:25,049][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=97.93%\n",
      "[ 2018-04-25 20:45:25,881][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=99.11%\n",
      "[ 2018-04-25 20:45:26,669][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=98.22%\n",
      "[ 2018-04-25 20:45:27,452][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=98.82%\n",
      "[ 2018-04-25 20:45:28,278][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=99.41%\n",
      "[ 2018-04-25 20:45:29,152][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-04-25 20:45:29,965][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=99.40%\n",
      "[ 2018-04-25 20:45:30,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=98.81%\n",
      "[ 2018-04-25 20:45:31,004][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=98.87%\n",
      "[ 2018-04-25 20:45:31,006][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=98.13%\n",
      "[ 2018-04-25 20:45:31,630][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=99.11%\n",
      "[ 2018-04-25 20:45:32,442][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=99.41%\n",
      "[ 2018-04-25 20:45:33,284][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=99.11%\n",
      "[ 2018-04-25 20:45:34,111][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=98.22%\n",
      "[ 2018-04-25 20:45:34,904][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-04-25 20:45:35,714][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=99.11%\n",
      "[ 2018-04-25 20:45:36,507][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=99.11%\n",
      "[ 2018-04-25 20:45:37,320][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-04-25 20:45:38,149][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=98.21%\n",
      "[ 2018-04-25 20:45:39,035][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=99.11%\n",
      "[ 2018-04-25 20:45:39,188][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=98.90%\n",
      "[ 2018-04-25 20:45:39,191][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=98.27%\n",
      "[ 2018-04-25 20:45:39,215][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=99.70%\n",
      "[ 2018-04-25 20:45:39,231][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=98.82%\n",
      "[ 2018-04-25 20:45:39,246][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=99.11%\n",
      "[ 2018-04-25 20:45:39,259][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-04-25 20:45:39,273][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=99.41%\n",
      "[ 2018-04-25 20:45:39,285][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=99.41%\n",
      "[ 2018-04-25 20:45:39,297][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=98.81%\n",
      "[ 2018-04-25 20:45:39,309][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=99.40%\n",
      "[ 2018-04-25 20:45:39,320][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=98.21%\n",
      "[ 2018-04-25 20:45:39,331][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=98.81%\n",
      "[ 2018-04-25 20:45:39,333][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=98.96%\n",
      "[ 2018-04-25 20:45:39,335][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-04-25 20:45:39,336][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=98.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:45:39,337][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=97.99%\n",
      "[ 2018-04-25 20:45:39,339][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:45:39,918][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=99.11%\n",
      "[ 2018-04-25 20:45:40,703][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=97.63%\n",
      "[ 2018-04-25 20:45:41,513][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=99.70%\n",
      "[ 2018-04-25 20:45:42,287][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=99.11%\n",
      "[ 2018-04-25 20:45:43,123][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=99.11%\n",
      "[ 2018-04-25 20:45:43,907][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=99.11%\n",
      "[ 2018-04-25 20:45:44,843][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=98.81%\n",
      "[ 2018-04-25 20:45:45,673][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=98.81%\n",
      "[ 2018-04-25 20:45:46,504][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=98.21%\n",
      "[ 2018-04-25 20:45:47,274][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=98.81%\n",
      "[ 2018-04-25 20:45:47,427][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=98.84%\n",
      "[ 2018-04-25 20:45:47,429][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=97.99%\n",
      "[ 2018-04-25 20:45:48,085][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=98.82%\n",
      "[ 2018-04-25 20:45:48,874][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=98.82%\n",
      "[ 2018-04-25 20:45:49,809][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=98.22%\n",
      "[ 2018-04-25 20:45:50,643][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=98.52%\n",
      "[ 2018-04-25 20:45:51,523][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=98.82%\n",
      "[ 2018-04-25 20:45:52,389][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=99.11%\n",
      "[ 2018-04-25 20:45:53,226][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=98.52%\n",
      "[ 2018-04-25 20:45:54,016][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=99.40%\n",
      "[ 2018-04-25 20:45:54,802][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=99.11%\n",
      "[ 2018-04-25 20:45:55,594][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=99.70%\n",
      "[ 2018-04-25 20:45:55,741][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=98.90%\n",
      "[ 2018-04-25 20:45:55,743][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=97.79%\n",
      "[ 2018-04-25 20:45:55,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=99.41%\n",
      "[ 2018-04-25 20:45:55,792][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=98.52%\n",
      "[ 2018-04-25 20:45:55,810][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=98.82%\n",
      "[ 2018-04-25 20:45:55,824][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=100.00%\n",
      "[ 2018-04-25 20:45:55,840][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=98.22%\n",
      "[ 2018-04-25 20:45:55,856][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=98.22%\n",
      "[ 2018-04-25 20:45:55,869][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=99.70%\n",
      "[ 2018-04-25 20:45:55,883][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=98.21%\n",
      "[ 2018-04-25 20:45:55,896][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=99.40%\n",
      "[ 2018-04-25 20:45:55,907][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=99.11%\n",
      "[ 2018-04-25 20:45:55,909][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=98.96%\n",
      "[ 2018-04-25 20:45:55,911][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-04-25 20:45:55,912][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=98.99%\n",
      "[ 2018-04-25 20:45:55,914][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=97.93%\n",
      "[ 2018-04-25 20:45:55,916][cascade_classifier.fit_transform] [layer=6] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:45:56,510][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_0.predict)=99.41%\n",
      "[ 2018-04-25 20:45:57,369][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_1.predict)=98.22%\n",
      "[ 2018-04-25 20:45:58,160][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_2.predict)=99.11%\n",
      "[ 2018-04-25 20:45:58,976][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_3.predict)=99.41%\n",
      "[ 2018-04-25 20:45:59,795][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-04-25 20:46:00,560][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_5.predict)=98.82%\n",
      "[ 2018-04-25 20:46:01,367][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_6.predict)=100.00%\n",
      "[ 2018-04-25 20:46:02,194][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-04-25 20:46:03,010][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_8.predict)=98.81%\n",
      "[ 2018-04-25 20:46:03,804][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_9.predict)=98.51%\n",
      "[ 2018-04-25 20:46:03,957][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_cv.predict)=98.99%\n",
      "[ 2018-04-25 20:46:03,959][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-04-25 20:46:04,720][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_0.predict)=99.41%\n",
      "[ 2018-04-25 20:46:05,523][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_1.predict)=99.41%\n",
      "[ 2018-04-25 20:46:06,355][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_2.predict)=99.41%\n",
      "[ 2018-04-25 20:46:07,205][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_3.predict)=99.41%\n",
      "[ 2018-04-25 20:46:08,036][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:46:08,860][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_5.predict)=98.82%\n",
      "[ 2018-04-25 20:46:09,694][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_6.predict)=97.63%\n",
      "[ 2018-04-25 20:46:10,479][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_7.predict)=99.40%\n",
      "[ 2018-04-25 20:46:11,270][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_8.predict)=99.11%\n",
      "[ 2018-04-25 20:46:12,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_9.predict)=98.81%\n",
      "[ 2018-04-25 20:46:12,243][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_cv.predict)=98.93%\n",
      "[ 2018-04-25 20:46:12,245][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-04-25 20:46:12,272][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_0.predict)=99.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:46:12,294][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_1.predict)=98.82%\n",
      "[ 2018-04-25 20:46:12,312][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_2.predict)=99.11%\n",
      "[ 2018-04-25 20:46:12,328][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_3.predict)=99.11%\n",
      "[ 2018-04-25 20:46:12,344][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_4.predict)=98.82%\n",
      "[ 2018-04-25 20:46:12,359][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_5.predict)=98.82%\n",
      "[ 2018-04-25 20:46:12,375][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_6.predict)=97.92%\n",
      "[ 2018-04-25 20:46:12,391][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_7.predict)=99.40%\n",
      "[ 2018-04-25 20:46:12,405][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_8.predict)=98.51%\n",
      "[ 2018-04-25 20:46:12,418][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_9.predict)=98.81%\n",
      "[ 2018-04-25 20:46:12,420][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_cv.predict)=98.87%\n",
      "[ 2018-04-25 20:46:12,422][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.test.predict)=97.79%\n",
      "[ 2018-04-25 20:46:12,423][cascade_classifier.calc_accuracy] Accuracy(layer_6 - train.classifier_average)=98.99%\n",
      "[ 2018-04-25 20:46:12,425][cascade_classifier.calc_accuracy] Accuracy(layer_6 - test.classifier_average)=97.79%\n",
      "[ 2018-04-25 20:46:12,427][cascade_classifier.fit_transform] [layer=7] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:46:13,073][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_0.predict)=98.22%\n",
      "[ 2018-04-25 20:46:13,838][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_1.predict)=99.11%\n",
      "[ 2018-04-25 20:46:14,644][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_2.predict)=98.82%\n",
      "[ 2018-04-25 20:46:15,472][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_3.predict)=99.41%\n",
      "[ 2018-04-25 20:46:16,301][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_4.predict)=99.41%\n",
      "[ 2018-04-25 20:46:17,138][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_5.predict)=98.82%\n",
      "[ 2018-04-25 20:46:17,929][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_6.predict)=99.11%\n",
      "[ 2018-04-25 20:46:18,829][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_7.predict)=99.40%\n",
      "[ 2018-04-25 20:46:19,647][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_8.predict)=98.81%\n",
      "[ 2018-04-25 20:46:20,429][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_9.predict)=98.21%\n",
      "[ 2018-04-25 20:46:20,581][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_cv.predict)=98.93%\n",
      "[ 2018-04-25 20:46:20,583][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.test.predict)=97.79%\n",
      "[ 2018-04-25 20:46:21,228][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_0.predict)=99.41%\n",
      "[ 2018-04-25 20:46:22,042][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_1.predict)=98.52%\n",
      "[ 2018-04-25 20:46:22,826][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_2.predict)=99.11%\n",
      "[ 2018-04-25 20:46:23,653][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_3.predict)=97.93%\n",
      "[ 2018-04-25 20:46:24,461][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:46:25,229][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_5.predict)=99.41%\n",
      "[ 2018-04-25 20:46:25,990][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_6.predict)=99.41%\n",
      "[ 2018-04-25 20:46:26,848][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-04-25 20:46:27,730][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_8.predict)=99.40%\n",
      "[ 2018-04-25 20:46:28,501][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_9.predict)=99.40%\n",
      "[ 2018-04-25 20:46:28,652][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_cv.predict)=98.96%\n",
      "[ 2018-04-25 20:46:28,655][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.test.predict)=97.79%\n",
      "[ 2018-04-25 20:46:28,679][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_0.predict)=99.11%\n",
      "[ 2018-04-25 20:46:28,695][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_1.predict)=99.41%\n",
      "[ 2018-04-25 20:46:28,710][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_2.predict)=98.22%\n",
      "[ 2018-04-25 20:46:28,724][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_3.predict)=98.82%\n",
      "[ 2018-04-25 20:46:28,738][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_4.predict)=98.82%\n",
      "[ 2018-04-25 20:46:28,751][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_5.predict)=99.41%\n",
      "[ 2018-04-25 20:46:28,764][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_6.predict)=99.11%\n",
      "[ 2018-04-25 20:46:28,777][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_7.predict)=98.81%\n",
      "[ 2018-04-25 20:46:28,790][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_8.predict)=99.40%\n",
      "[ 2018-04-25 20:46:28,801][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_9.predict)=98.51%\n",
      "[ 2018-04-25 20:46:28,803][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_cv.predict)=98.96%\n",
      "[ 2018-04-25 20:46:28,804][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.test.predict)=97.79%\n",
      "[ 2018-04-25 20:46:28,805][cascade_classifier.calc_accuracy] Accuracy(layer_7 - train.classifier_average)=98.99%\n",
      "[ 2018-04-25 20:46:28,807][cascade_classifier.calc_accuracy] Accuracy(layer_7 - test.classifier_average)=97.79%\n",
      "[ 2018-04-25 20:46:28,809][cascade_classifier.fit_transform] [layer=8] look_indexs=[0], X_cur_train.shape=(3373, 11), X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:46:29,396][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_0.predict)=99.41%\n",
      "[ 2018-04-25 20:46:30,214][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_1.predict)=99.11%\n",
      "[ 2018-04-25 20:46:31,019][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_2.predict)=98.82%\n",
      "[ 2018-04-25 20:46:31,865][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_3.predict)=98.82%\n",
      "[ 2018-04-25 20:46:32,725][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_4.predict)=98.52%\n",
      "[ 2018-04-25 20:46:33,533][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_5.predict)=99.11%\n",
      "[ 2018-04-25 20:46:34,363][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_6.predict)=99.11%\n",
      "[ 2018-04-25 20:46:35,239][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_7.predict)=98.21%\n",
      "[ 2018-04-25 20:46:36,081][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_8.predict)=99.40%\n",
      "[ 2018-04-25 20:46:36,920][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_9.predict)=99.40%\n",
      "[ 2018-04-25 20:46:37,078][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_cv.predict)=98.99%\n",
      "[ 2018-04-25 20:46:37,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.test.predict)=97.79%\n",
      "[ 2018-04-25 20:46:37,759][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_0.predict)=99.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:46:38,596][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_1.predict)=98.22%\n",
      "[ 2018-04-25 20:46:39,387][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_2.predict)=99.41%\n",
      "[ 2018-04-25 20:46:40,207][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_3.predict)=99.41%\n",
      "[ 2018-04-25 20:46:40,981][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:46:41,746][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_5.predict)=99.41%\n",
      "[ 2018-04-25 20:46:42,517][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_6.predict)=98.81%\n",
      "[ 2018-04-25 20:46:43,327][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_7.predict)=99.40%\n",
      "[ 2018-04-25 20:46:44,130][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_8.predict)=98.51%\n",
      "[ 2018-04-25 20:46:45,049][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_9.predict)=98.81%\n",
      "[ 2018-04-25 20:46:45,204][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_cv.predict)=98.93%\n",
      "[ 2018-04-25 20:46:45,205][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.test.predict)=97.79%\n",
      "[ 2018-04-25 20:46:45,231][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_0.predict)=97.63%\n",
      "[ 2018-04-25 20:46:45,255][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_1.predict)=99.41%\n",
      "[ 2018-04-25 20:46:45,274][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_2.predict)=98.52%\n",
      "[ 2018-04-25 20:46:45,295][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_3.predict)=99.70%\n",
      "[ 2018-04-25 20:46:45,315][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_4.predict)=97.93%\n",
      "[ 2018-04-25 20:46:45,335][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_5.predict)=99.11%\n",
      "[ 2018-04-25 20:46:45,356][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_6.predict)=99.41%\n",
      "[ 2018-04-25 20:46:45,373][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_7.predict)=99.11%\n",
      "[ 2018-04-25 20:46:45,389][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_8.predict)=99.70%\n",
      "[ 2018-04-25 20:46:45,405][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_9.predict)=98.81%\n",
      "[ 2018-04-25 20:46:45,407][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_cv.predict)=98.93%\n",
      "[ 2018-04-25 20:46:45,409][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.test.predict)=97.79%\n",
      "[ 2018-04-25 20:46:45,411][cascade_classifier.calc_accuracy] Accuracy(layer_8 - train.classifier_average)=98.96%\n",
      "[ 2018-04-25 20:46:45,412][cascade_classifier.calc_accuracy] Accuracy(layer_8 - test.classifier_average)=97.79%\n",
      "[ 2018-04-25 20:46:45,414][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=6, accuracy_train=98.99%, accuracy_test=97.93%\n"
     ]
    }
   ],
   "source": [
    "    # X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 20:46:45,445][cascade_classifier.transform] X_groups_test.shape=[(1446, 5)]\n",
      "[ 2018-04-25 20:46:45,447][cascade_classifier.transform] group_dims=[5]\n",
      "[ 2018-04-25 20:46:45,449][cascade_classifier.transform] X_test.shape=(1446, 5)\n",
      "[ 2018-04-25 20:46:45,451][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(1446, 5)\n",
      "[ 2018-04-25 20:46:48,497][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:46:51,593][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:46:54,599][cascade_classifier.transform] [layer=3] look_indexs=[0], X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:46:57,735][cascade_classifier.transform] [layer=4] look_indexs=[0], X_cur_test.shape=(1446, 11)\n",
      "[ 2018-04-25 20:47:00,840][cascade_classifier.transform] [layer=5] look_indexs=[0], X_cur_test.shape=(1446, 11)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 97.925311 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.6648 - acc: 0.9486     \n",
      "Epoch 2/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.4706 - acc: 0.9486     \n",
      "Epoch 3/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2167 - acc: 0.9486     \n",
      "Epoch 4/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1995 - acc: 0.9486     \n",
      "Epoch 5/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1990 - acc: 0.9486     \n",
      "Epoch 6/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1989 - acc: 0.9486     \n",
      "Epoch 7/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1989 - acc: 0.9486     \n",
      "Epoch 8/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1988 - acc: 0.9486     \n",
      "Epoch 9/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1986 - acc: 0.9486     \n",
      "Epoch 10/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1985 - acc: 0.9486     \n",
      "Epoch 11/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1984 - acc: 0.9486     \n",
      "Epoch 12/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1987 - acc: 0.9486     \n",
      "Epoch 13/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1981 - acc: 0.9486     \n",
      "Epoch 14/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1979 - acc: 0.9486     \n",
      "Epoch 15/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1981 - acc: 0.9486     \n",
      "Epoch 16/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1977 - acc: 0.9486     \n",
      "Epoch 17/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1977 - acc: 0.9486     \n",
      "Epoch 18/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1975 - acc: 0.9486     \n",
      "Epoch 19/100\n",
      "3035/3035 [==============================] - ETA: 0s - loss: 0.1992 - acc: 0.948 - 0s - loss: 0.1975 - acc: 0.9486     \n",
      "Epoch 20/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1971 - acc: 0.9486     \n",
      "Epoch 21/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1972 - acc: 0.9486     \n",
      "Epoch 22/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1971 - acc: 0.9486     \n",
      "Epoch 23/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1970 - acc: 0.9486     \n",
      "Epoch 24/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1968 - acc: 0.9486     \n",
      "Epoch 25/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1966 - acc: 0.9486     \n",
      "Epoch 26/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1963 - acc: 0.9486     \n",
      "Epoch 27/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1966 - acc: 0.9486     \n",
      "Epoch 28/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1964 - acc: 0.9486     \n",
      "Epoch 29/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1961 - acc: 0.9486     \n",
      "Epoch 30/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1962 - acc: 0.9486     \n",
      "Epoch 31/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1961 - acc: 0.9486     \n",
      "Epoch 32/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1959 - acc: 0.9486     \n",
      "Epoch 33/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1957 - acc: 0.9486     \n",
      "Epoch 34/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1956 - acc: 0.9486     \n",
      "Epoch 35/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1954 - acc: 0.9486     \n",
      "Epoch 36/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1953 - acc: 0.9486     \n",
      "Epoch 37/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1951 - acc: 0.9486     \n",
      "Epoch 38/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1948 - acc: 0.9486     \n",
      "Epoch 39/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1951 - acc: 0.9486     \n",
      "Epoch 40/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1948 - acc: 0.9486     \n",
      "Epoch 41/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1946 - acc: 0.9486     \n",
      "Epoch 42/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1946 - acc: 0.9486     \n",
      "Epoch 43/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1945 - acc: 0.9486     \n",
      "Epoch 44/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1942 - acc: 0.9486     \n",
      "Epoch 45/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1942 - acc: 0.9486     \n",
      "Epoch 46/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1944 - acc: 0.9486     \n",
      "Epoch 47/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1939 - acc: 0.9486     \n",
      "Epoch 48/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1939 - acc: 0.9486     \n",
      "Epoch 49/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1938 - acc: 0.9486     \n",
      "Epoch 50/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1935 - acc: 0.9486     \n",
      "Epoch 51/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1934 - acc: 0.9486     \n",
      "Epoch 52/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1930 - acc: 0.9486     \n",
      "Epoch 53/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1934 - acc: 0.9486     \n",
      "Epoch 54/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1933 - acc: 0.9486     \n",
      "Epoch 55/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1929 - acc: 0.9486     \n",
      "Epoch 56/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1928 - acc: 0.9486     \n",
      "Epoch 57/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1927 - acc: 0.9486     \n",
      "Epoch 58/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1924 - acc: 0.9486     \n",
      "Epoch 59/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1925 - acc: 0.9486     \n",
      "Epoch 60/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1922 - acc: 0.9486     \n",
      "Epoch 61/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1920 - acc: 0.9486     \n",
      "Epoch 62/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1920 - acc: 0.9486     \n",
      "Epoch 63/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1920 - acc: 0.9486     \n",
      "Epoch 64/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1922 - acc: 0.9486     \n",
      "Epoch 65/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1917 - acc: 0.9486     \n",
      "Epoch 66/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1914 - acc: 0.9486     \n",
      "Epoch 67/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1915 - acc: 0.9486     \n",
      "Epoch 68/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1913 - acc: 0.9486     \n",
      "Epoch 69/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1912 - acc: 0.9486     \n",
      "Epoch 70/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1910 - acc: 0.9486     \n",
      "Epoch 71/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1908 - acc: 0.9486     \n",
      "Epoch 72/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1908 - acc: 0.9486     \n",
      "Epoch 73/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1909 - acc: 0.9486     \n",
      "Epoch 74/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1905 - acc: 0.9486     \n",
      "Epoch 75/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1906 - acc: 0.9486     \n",
      "Epoch 76/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1901 - acc: 0.9486     \n",
      "Epoch 77/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1903 - acc: 0.9486     \n",
      "Epoch 78/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1900 - acc: 0.9486     \n",
      "Epoch 79/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1901 - acc: 0.9486     \n",
      "Epoch 80/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1897 - acc: 0.9486     \n",
      "Epoch 81/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1894 - acc: 0.9486     \n",
      "Epoch 82/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1895 - acc: 0.9486     \n",
      "Epoch 83/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1889 - acc: 0.9486     \n",
      "Epoch 84/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1892 - acc: 0.9486     \n",
      "Epoch 85/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1887 - acc: 0.9486     \n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 0s - loss: 0.1888 - acc: 0.9486     \n",
      "Epoch 87/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1888 - acc: 0.9486     \n",
      "Epoch 88/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1887 - acc: 0.9486     \n",
      "Epoch 89/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1884 - acc: 0.9486     \n",
      "Epoch 90/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1883 - acc: 0.9486     \n",
      "Epoch 91/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1881 - acc: 0.9486     \n",
      "Epoch 92/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1883 - acc: 0.9486     \n",
      "Epoch 93/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1881 - acc: 0.9486     \n",
      "Epoch 94/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1875 - acc: 0.9486     \n",
      "Epoch 95/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1873 - acc: 0.9486     \n",
      "Epoch 96/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1875 - acc: 0.9486     \n",
      "Epoch 97/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1868 - acc: 0.9486     \n",
      "Epoch 98/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1869 - acc: 0.9486     \n",
      "Epoch 99/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1867 - acc: 0.9486     \n",
      "Epoch 100/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1864 - acc: 0.9486     \n",
      " 32/338 [=>............................] - ETA: 0sEpoch 1/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.6726 - acc: 0.9384     \n",
      "Epoch 2/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.6331 - acc: 0.9470     \n",
      "Epoch 3/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.5970 - acc: 0.9470     \n",
      "Epoch 4/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.5637 - acc: 0.9470     \n",
      "Epoch 5/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.5332 - acc: 0.9470     \n",
      "Epoch 6/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.5052 - acc: 0.9470     \n",
      "Epoch 7/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.4796 - acc: 0.9470     \n",
      "Epoch 8/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.4561 - acc: 0.9470     \n",
      "Epoch 9/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.4346 - acc: 0.9470     \n",
      "Epoch 10/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.4149 - acc: 0.9470     \n",
      "Epoch 11/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.3969 - acc: 0.9470     \n",
      "Epoch 12/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.3804 - acc: 0.9470     \n",
      "Epoch 13/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.3653 - acc: 0.9470     \n",
      "Epoch 14/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.3515 - acc: 0.9470     \n",
      "Epoch 15/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.3389 - acc: 0.9470     \n",
      "Epoch 16/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.3274 - acc: 0.9470     \n",
      "Epoch 17/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.3168 - acc: 0.9470     \n",
      "Epoch 18/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.3071 - acc: 0.9470     \n",
      "Epoch 19/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2982 - acc: 0.9470     \n",
      "Epoch 20/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2901 - acc: 0.9470     \n",
      "Epoch 21/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2826 - acc: 0.9470     \n",
      "Epoch 22/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2758 - acc: 0.9470     \n",
      "Epoch 23/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2696 - acc: 0.9470     \n",
      "Epoch 24/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2639 - acc: 0.9470     \n",
      "Epoch 25/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2586 - acc: 0.9470     \n",
      "Epoch 26/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2538 - acc: 0.9470     \n",
      "Epoch 27/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2495 - acc: 0.9470     \n",
      "Epoch 28/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2455 - acc: 0.9470     \n",
      "Epoch 29/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2418 - acc: 0.9470     \n",
      "Epoch 30/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2385 - acc: 0.9470     \n",
      "Epoch 31/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2354 - acc: 0.9470     \n",
      "Epoch 32/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2326 - acc: 0.9470     \n",
      "Epoch 33/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2301 - acc: 0.9470     \n",
      "Epoch 34/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2277 - acc: 0.9470     - ETA: 0s - loss: 0.2382 - acc: 0.9\n",
      "Epoch 35/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2256 - acc: 0.9470     \n",
      "Epoch 36/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2237 - acc: 0.9470     \n",
      "Epoch 37/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2220 - acc: 0.9470     \n",
      "Epoch 38/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2204 - acc: 0.9470     \n",
      "Epoch 39/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2190 - acc: 0.9470     \n",
      "Epoch 40/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2177 - acc: 0.9470     \n",
      "Epoch 41/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2165 - acc: 0.9470     \n",
      "Epoch 42/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2155 - acc: 0.9470     \n",
      "Epoch 43/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2145 - acc: 0.9470     \n",
      "Epoch 44/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2137 - acc: 0.9470     \n",
      "Epoch 45/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2129 - acc: 0.9470     \n",
      "Epoch 46/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2122 - acc: 0.9470     \n",
      "Epoch 47/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2116 - acc: 0.9470     - ETA: 0s - loss: 0.1963 - acc: 0.95\n",
      "Epoch 48/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2111 - acc: 0.9470     \n",
      "Epoch 49/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2106 - acc: 0.9470     \n",
      "Epoch 50/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2102 - acc: 0.9470     \n",
      "Epoch 51/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2098 - acc: 0.9470     \n",
      "Epoch 52/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2095 - acc: 0.9470     \n",
      "Epoch 53/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2092 - acc: 0.9470     \n",
      "Epoch 54/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2089 - acc: 0.9470     \n",
      "Epoch 55/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2087 - acc: 0.9470     \n",
      "Epoch 56/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2085 - acc: 0.9470     \n",
      "Epoch 57/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2083 - acc: 0.9470     \n",
      "Epoch 58/100\n",
      "3035/3035 [==============================] - ETA: 0s - loss: 0.2178 - acc: 0.943 - 0s - loss: 0.2082 - acc: 0.9470     \n",
      "Epoch 59/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2081 - acc: 0.9470     \n",
      "Epoch 60/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2080 - acc: 0.9470     \n",
      "Epoch 61/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2079 - acc: 0.9470     \n",
      "Epoch 62/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2078 - acc: 0.9470     \n",
      "Epoch 63/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2077 - acc: 0.9470     \n",
      "Epoch 64/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2077 - acc: 0.9470     \n",
      "Epoch 65/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2076 - acc: 0.9470     \n",
      "Epoch 66/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2076 - acc: 0.9470     \n",
      "Epoch 67/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2076 - acc: 0.9470     \n",
      "Epoch 68/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2075 - acc: 0.9470     \n",
      "Epoch 69/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2075 - acc: 0.9470     \n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 0s - loss: 0.2075 - acc: 0.9470     \n",
      "Epoch 71/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2075 - acc: 0.9470     \n",
      "Epoch 72/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2075 - acc: 0.9470     \n",
      "Epoch 73/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 74/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 75/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 76/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 77/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 78/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 79/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 80/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 81/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 82/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 83/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 84/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 85/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 86/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 87/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 88/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 89/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 90/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 91/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 92/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 93/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 94/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 95/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 96/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 97/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 98/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 99/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 100/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      " 32/338 [=>............................] - ETA: 0sEpoch 1/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.6582 - acc: 0.9470     \n",
      "Epoch 2/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.3789 - acc: 0.9470     \n",
      "Epoch 3/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2048 - acc: 0.9470     \n",
      "Epoch 4/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2040 - acc: 0.9470     \n",
      "Epoch 5/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2038 - acc: 0.9470     \n",
      "Epoch 6/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2042 - acc: 0.9470     \n",
      "Epoch 7/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2035 - acc: 0.9470     \n",
      "Epoch 8/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2035 - acc: 0.9470     \n",
      "Epoch 9/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2035 - acc: 0.9470     \n",
      "Epoch 10/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2028 - acc: 0.9470     \n",
      "Epoch 11/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2029 - acc: 0.9470     \n",
      "Epoch 12/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2026 - acc: 0.9470     \n",
      "Epoch 13/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2028 - acc: 0.9470     \n",
      "Epoch 14/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2023 - acc: 0.9470     \n",
      "Epoch 15/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2022 - acc: 0.9470     \n",
      "Epoch 16/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2020 - acc: 0.9470     \n",
      "Epoch 17/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2020 - acc: 0.9470     \n",
      "Epoch 18/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2014 - acc: 0.9470     \n",
      "Epoch 19/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2016 - acc: 0.9470     \n",
      "Epoch 20/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2012 - acc: 0.9470     \n",
      "Epoch 21/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2014 - acc: 0.9470     \n",
      "Epoch 22/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2008 - acc: 0.9470     \n",
      "Epoch 23/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2009 - acc: 0.9470     \n",
      "Epoch 24/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2009 - acc: 0.9470     \n",
      "Epoch 25/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2004 - acc: 0.9470     \n",
      "Epoch 26/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2003 - acc: 0.9470     \n",
      "Epoch 27/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2000 - acc: 0.9470     \n",
      "Epoch 28/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2000 - acc: 0.9470     \n",
      "Epoch 29/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.2000 - acc: 0.9470     \n",
      "Epoch 30/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1994 - acc: 0.9470     \n",
      "Epoch 31/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1997 - acc: 0.9470     \n",
      "Epoch 32/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1994 - acc: 0.9470     \n",
      "Epoch 33/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1991 - acc: 0.9470     \n",
      "Epoch 34/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1989 - acc: 0.9470     \n",
      "Epoch 35/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1991 - acc: 0.9470     \n",
      "Epoch 36/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1992 - acc: 0.9470     \n",
      "Epoch 37/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1986 - acc: 0.9470     \n",
      "Epoch 38/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1986 - acc: 0.9470     \n",
      "Epoch 39/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1982 - acc: 0.9470     \n",
      "Epoch 40/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1982 - acc: 0.9470     \n",
      "Epoch 41/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1979 - acc: 0.9470     \n",
      "Epoch 42/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1977 - acc: 0.9470     \n",
      "Epoch 43/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1973 - acc: 0.9470     \n",
      "Epoch 44/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1972 - acc: 0.9470     \n",
      "Epoch 45/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1973 - acc: 0.9470     \n",
      "Epoch 46/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1971 - acc: 0.9470     \n",
      "Epoch 47/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1966 - acc: 0.9470     \n",
      "Epoch 48/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1966 - acc: 0.9470     \n",
      "Epoch 49/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1961 - acc: 0.9470     \n",
      "Epoch 50/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1962 - acc: 0.9470     \n",
      "Epoch 51/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1958 - acc: 0.9470     \n",
      "Epoch 52/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1957 - acc: 0.9470     \n",
      "Epoch 53/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1955 - acc: 0.9470     \n",
      "Epoch 54/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1955 - acc: 0.9470     \n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 0s - loss: 0.1952 - acc: 0.9470     \n",
      "Epoch 56/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1952 - acc: 0.9470     \n",
      "Epoch 57/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1949 - acc: 0.9470     \n",
      "Epoch 58/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1952 - acc: 0.9470     \n",
      "Epoch 59/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1948 - acc: 0.9470     \n",
      "Epoch 60/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1942 - acc: 0.9470     \n",
      "Epoch 61/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1941 - acc: 0.9470     \n",
      "Epoch 62/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1939 - acc: 0.9470     \n",
      "Epoch 63/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1939 - acc: 0.9470     \n",
      "Epoch 64/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1935 - acc: 0.9470     \n",
      "Epoch 65/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1937 - acc: 0.9470     \n",
      "Epoch 66/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1935 - acc: 0.9470     \n",
      "Epoch 67/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1930 - acc: 0.9470     \n",
      "Epoch 68/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1926 - acc: 0.9470     \n",
      "Epoch 69/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1928 - acc: 0.9470     \n",
      "Epoch 70/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1926 - acc: 0.9470     \n",
      "Epoch 71/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1928 - acc: 0.9470     \n",
      "Epoch 72/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1918 - acc: 0.9470     \n",
      "Epoch 73/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1919 - acc: 0.9470     \n",
      "Epoch 74/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1916 - acc: 0.9470     \n",
      "Epoch 75/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1921 - acc: 0.9470     \n",
      "Epoch 76/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1908 - acc: 0.9470     \n",
      "Epoch 77/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1912 - acc: 0.9470     \n",
      "Epoch 78/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1905 - acc: 0.9470     \n",
      "Epoch 79/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1900 - acc: 0.9470     \n",
      "Epoch 80/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1897 - acc: 0.9470     \n",
      "Epoch 81/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1898 - acc: 0.9470     \n",
      "Epoch 82/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1890 - acc: 0.9470     \n",
      "Epoch 83/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1888 - acc: 0.9470     \n",
      "Epoch 84/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1884 - acc: 0.9470     \n",
      "Epoch 85/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1881 - acc: 0.9470     \n",
      "Epoch 86/100\n",
      "3035/3035 [==============================] - ETA: 0s - loss: 0.1822 - acc: 0.948 - 0s - loss: 0.1878 - acc: 0.9470     \n",
      "Epoch 87/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1873 - acc: 0.9470     \n",
      "Epoch 88/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1870 - acc: 0.9470     \n",
      "Epoch 89/100\n",
      "3035/3035 [==============================] - ETA: 0s - loss: 0.1851 - acc: 0.948 - 0s - loss: 0.1865 - acc: 0.9470     \n",
      "Epoch 90/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1862 - acc: 0.9470     \n",
      "Epoch 91/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1862 - acc: 0.9470     - ETA: 0s - loss: 0.2110 - acc: 0.938 - ETA: 0s - loss: 0.1929 - acc: 0.944\n",
      "Epoch 92/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1859 - acc: 0.9470     \n",
      "Epoch 93/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1850 - acc: 0.9470     \n",
      "Epoch 94/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1845 - acc: 0.9470     \n",
      "Epoch 95/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1848 - acc: 0.9470     \n",
      "Epoch 96/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1840 - acc: 0.9470     \n",
      "Epoch 97/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1832 - acc: 0.9470     \n",
      "Epoch 98/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1829 - acc: 0.9470     \n",
      "Epoch 99/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1823 - acc: 0.9470     - ETA: 0s - loss: 0.1834 - acc: 0.94\n",
      "Epoch 100/100\n",
      "3035/3035 [==============================] - 0s - loss: 0.1815 - acc: 0.9470     \n",
      " 32/338 [=>............................] - ETA: 0sEpoch 1/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.6683 - acc: 0.9499     \n",
      "Epoch 2/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5023 - acc: 0.9499     \n",
      "Epoch 3/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2234 - acc: 0.9499     \n",
      "Epoch 4/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1951 - acc: 0.9499     \n",
      "Epoch 5/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1948 - acc: 0.9499     \n",
      "Epoch 6/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1947 - acc: 0.9499     \n",
      "Epoch 7/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1947 - acc: 0.9499     \n",
      "Epoch 8/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1944 - acc: 0.9499     \n",
      "Epoch 9/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1946 - acc: 0.9499     \n",
      "Epoch 10/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1944 - acc: 0.9499     \n",
      "Epoch 11/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1943 - acc: 0.9499     \n",
      "Epoch 12/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1939 - acc: 0.9499     \n",
      "Epoch 13/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1937 - acc: 0.9499     \n",
      "Epoch 14/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1938 - acc: 0.9499     \n",
      "Epoch 15/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1937 - acc: 0.9499     \n",
      "Epoch 16/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1934 - acc: 0.9499     \n",
      "Epoch 17/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1932 - acc: 0.9499     \n",
      "Epoch 18/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1929 - acc: 0.9499     \n",
      "Epoch 19/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1932 - acc: 0.9499     \n",
      "Epoch 20/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1930 - acc: 0.9499     \n",
      "Epoch 21/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1925 - acc: 0.9499     \n",
      "Epoch 22/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1927 - acc: 0.9499     \n",
      "Epoch 23/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1924 - acc: 0.9499     \n",
      "Epoch 24/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1923 - acc: 0.9499     \n",
      "Epoch 25/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1922 - acc: 0.9499     \n",
      "Epoch 26/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1922 - acc: 0.9499     \n",
      "Epoch 27/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1920 - acc: 0.9499     \n",
      "Epoch 28/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1918 - acc: 0.9499     \n",
      "Epoch 29/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1916 - acc: 0.9499     \n",
      "Epoch 30/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1914 - acc: 0.9499     \n",
      "Epoch 31/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1913 - acc: 0.9499     \n",
      "Epoch 32/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1910 - acc: 0.9499     \n",
      "Epoch 33/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1915 - acc: 0.9499     \n",
      "Epoch 34/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1909 - acc: 0.9499     \n",
      "Epoch 35/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1908 - acc: 0.9499     \n",
      "Epoch 36/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1909 - acc: 0.9499     \n",
      "Epoch 37/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1905 - acc: 0.9499     \n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 0s - loss: 0.1903 - acc: 0.9499     \n",
      "Epoch 39/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1908 - acc: 0.9499     \n",
      "Epoch 40/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1900 - acc: 0.9499     \n",
      "Epoch 41/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1899 - acc: 0.9499     \n",
      "Epoch 42/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1899 - acc: 0.9499     \n",
      "Epoch 43/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1897 - acc: 0.9499     \n",
      "Epoch 44/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1898 - acc: 0.9499     \n",
      "Epoch 45/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1899 - acc: 0.9499     \n",
      "Epoch 46/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1891 - acc: 0.9499     \n",
      "Epoch 47/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1891 - acc: 0.9499     \n",
      "Epoch 48/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1891 - acc: 0.9499     \n",
      "Epoch 49/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1889 - acc: 0.9499     \n",
      "Epoch 50/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1891 - acc: 0.9499     \n",
      "Epoch 51/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1885 - acc: 0.9499     \n",
      "Epoch 52/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1884 - acc: 0.9499     \n",
      "Epoch 53/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1886 - acc: 0.9499     \n",
      "Epoch 54/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1880 - acc: 0.9499     \n",
      "Epoch 55/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1883 - acc: 0.9499     \n",
      "Epoch 56/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1879 - acc: 0.9499     \n",
      "Epoch 57/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1879 - acc: 0.9499     \n",
      "Epoch 58/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1877 - acc: 0.9499     \n",
      "Epoch 59/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1875 - acc: 0.9499     \n",
      "Epoch 60/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1874 - acc: 0.9499     \n",
      "Epoch 61/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1874 - acc: 0.9499     \n",
      "Epoch 62/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1870 - acc: 0.9499     \n",
      "Epoch 63/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1871 - acc: 0.9499     \n",
      "Epoch 64/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1871 - acc: 0.9499     \n",
      "Epoch 65/100\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.1863 - acc: 0.949 - 0s - loss: 0.1867 - acc: 0.9499     \n",
      "Epoch 66/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1867 - acc: 0.9499     \n",
      "Epoch 67/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1866 - acc: 0.9499     \n",
      "Epoch 68/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1868 - acc: 0.9499     \n",
      "Epoch 69/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1861 - acc: 0.9499     \n",
      "Epoch 70/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1863 - acc: 0.9499     \n",
      "Epoch 71/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1858 - acc: 0.9499     \n",
      "Epoch 72/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1857 - acc: 0.9499     \n",
      "Epoch 73/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1857 - acc: 0.9499     \n",
      "Epoch 74/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1855 - acc: 0.9499     \n",
      "Epoch 75/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1855 - acc: 0.9499     \n",
      "Epoch 76/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1854 - acc: 0.9499     \n",
      "Epoch 77/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1849 - acc: 0.9499     \n",
      "Epoch 78/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1850 - acc: 0.9499     \n",
      "Epoch 79/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1849 - acc: 0.9499     \n",
      "Epoch 80/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1852 - acc: 0.9499     \n",
      "Epoch 81/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1846 - acc: 0.9499     \n",
      "Epoch 82/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1842 - acc: 0.9499     \n",
      "Epoch 83/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1842 - acc: 0.9499     \n",
      "Epoch 84/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1843 - acc: 0.9499     \n",
      "Epoch 85/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1841 - acc: 0.9499     \n",
      "Epoch 86/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1839 - acc: 0.9499     \n",
      "Epoch 87/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1835 - acc: 0.9499     \n",
      "Epoch 88/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1834 - acc: 0.9499     \n",
      "Epoch 89/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1831 - acc: 0.9499     \n",
      "Epoch 90/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1829 - acc: 0.9499     \n",
      "Epoch 91/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1832 - acc: 0.9499     \n",
      "Epoch 92/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1829 - acc: 0.9499     \n",
      "Epoch 93/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1826 - acc: 0.9499     \n",
      "Epoch 94/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1825 - acc: 0.9499     \n",
      "Epoch 95/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1823 - acc: 0.9499     \n",
      "Epoch 96/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1820 - acc: 0.9499     \n",
      "Epoch 97/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1818 - acc: 0.9499     \n",
      "Epoch 98/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1815 - acc: 0.9499     \n",
      "Epoch 99/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1813 - acc: 0.9499     \n",
      "Epoch 100/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1813 - acc: 0.9499     \n",
      " 32/337 [=>............................] - ETA: 0sEpoch 1/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.6685 - acc: 0.9470     \n",
      "Epoch 2/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5519 - acc: 0.9470     \n",
      "Epoch 3/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2973 - acc: 0.9470     \n",
      "Epoch 4/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2074 - acc: 0.9470     \n",
      "Epoch 5/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2040 - acc: 0.9470     \n",
      "Epoch 6/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2039 - acc: 0.9470     \n",
      "Epoch 7/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2038 - acc: 0.9470     \n",
      "Epoch 8/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2040 - acc: 0.9470     \n",
      "Epoch 9/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2035 - acc: 0.9470     \n",
      "Epoch 10/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2035 - acc: 0.9470     \n",
      "Epoch 11/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2035 - acc: 0.9470     \n",
      "Epoch 12/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2036 - acc: 0.9470     \n",
      "Epoch 13/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2032 - acc: 0.9470     \n",
      "Epoch 14/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2032 - acc: 0.9470     \n",
      "Epoch 15/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2030 - acc: 0.9470     \n",
      "Epoch 16/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2029 - acc: 0.9470     \n",
      "Epoch 17/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2028 - acc: 0.9470     \n",
      "Epoch 18/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2027 - acc: 0.9470     \n",
      "Epoch 19/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2027 - acc: 0.9470     \n",
      "Epoch 20/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2023 - acc: 0.9470     \n",
      "Epoch 21/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2027 - acc: 0.9470     \n",
      "Epoch 22/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2023 - acc: 0.9470     \n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 0s - loss: 0.2023 - acc: 0.9470     \n",
      "Epoch 24/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2021 - acc: 0.9470     \n",
      "Epoch 25/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2019 - acc: 0.9470     \n",
      "Epoch 26/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2021 - acc: 0.9470     \n",
      "Epoch 27/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2017 - acc: 0.9470     \n",
      "Epoch 28/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2017 - acc: 0.9470     \n",
      "Epoch 29/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2016 - acc: 0.9470     \n",
      "Epoch 30/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2015 - acc: 0.9470     \n",
      "Epoch 31/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2013 - acc: 0.9470     \n",
      "Epoch 32/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2012 - acc: 0.9470     \n",
      "Epoch 33/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2012 - acc: 0.9470     \n",
      "Epoch 34/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2011 - acc: 0.9470     \n",
      "Epoch 35/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2012 - acc: 0.9470     \n",
      "Epoch 36/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2008 - acc: 0.9470     \n",
      "Epoch 37/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2006 - acc: 0.9470     \n",
      "Epoch 38/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2006 - acc: 0.9470     \n",
      "Epoch 39/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2004 - acc: 0.9470     \n",
      "Epoch 40/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2004 - acc: 0.9470     \n",
      "Epoch 41/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2004 - acc: 0.9470     - ETA: 0s - loss: 0.1707 - acc: 0.9\n",
      "Epoch 42/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2003 - acc: 0.9470     \n",
      "Epoch 43/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2002 - acc: 0.9470     \n",
      "Epoch 44/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2000 - acc: 0.9470     \n",
      "Epoch 45/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2000 - acc: 0.9470     \n",
      "Epoch 46/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1998 - acc: 0.9470     \n",
      "Epoch 47/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1996 - acc: 0.9470     \n",
      "Epoch 48/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1995 - acc: 0.9470     \n",
      "Epoch 49/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1994 - acc: 0.9470     \n",
      "Epoch 50/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1994 - acc: 0.9470     \n",
      "Epoch 51/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1993 - acc: 0.9470     \n",
      "Epoch 52/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1991 - acc: 0.9470     \n",
      "Epoch 53/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1989 - acc: 0.9470     \n",
      "Epoch 54/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9470     \n",
      "Epoch 55/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9470     \n",
      "Epoch 56/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9470     \n",
      "Epoch 57/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1986 - acc: 0.9470     \n",
      "Epoch 58/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1985 - acc: 0.9470     \n",
      "Epoch 59/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1983 - acc: 0.9470     \n",
      "Epoch 60/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1983 - acc: 0.9470     \n",
      "Epoch 61/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1981 - acc: 0.9470     \n",
      "Epoch 62/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1981 - acc: 0.9470     \n",
      "Epoch 63/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1981 - acc: 0.9470     \n",
      "Epoch 64/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1978 - acc: 0.9470     \n",
      "Epoch 65/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1978 - acc: 0.9470     \n",
      "Epoch 66/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1977 - acc: 0.9470     \n",
      "Epoch 67/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1974 - acc: 0.9470     \n",
      "Epoch 68/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1976 - acc: 0.9470     \n",
      "Epoch 69/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1972 - acc: 0.9470     \n",
      "Epoch 70/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1972 - acc: 0.9470     \n",
      "Epoch 71/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1971 - acc: 0.9470     \n",
      "Epoch 72/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1969 - acc: 0.9470     \n",
      "Epoch 73/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1970 - acc: 0.9470     \n",
      "Epoch 74/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1968 - acc: 0.9470     \n",
      "Epoch 75/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1965 - acc: 0.9470     \n",
      "Epoch 76/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1967 - acc: 0.9470     \n",
      "Epoch 77/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1964 - acc: 0.9470     \n",
      "Epoch 78/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1969 - acc: 0.9470     \n",
      "Epoch 79/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1962 - acc: 0.9470     \n",
      "Epoch 80/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1962 - acc: 0.9470     \n",
      "Epoch 81/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1960 - acc: 0.9470     \n",
      "Epoch 82/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1960 - acc: 0.9470     \n",
      "Epoch 83/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1963 - acc: 0.9470     \n",
      "Epoch 84/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1959 - acc: 0.9470     \n",
      "Epoch 85/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1955 - acc: 0.9470     \n",
      "Epoch 86/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1957 - acc: 0.9470     \n",
      "Epoch 87/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1954 - acc: 0.9470     \n",
      "Epoch 88/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1952 - acc: 0.9470     \n",
      "Epoch 89/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1955 - acc: 0.9470     \n",
      "Epoch 90/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1951 - acc: 0.9470     \n",
      "Epoch 91/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1951 - acc: 0.9470     \n",
      "Epoch 92/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1948 - acc: 0.9470     \n",
      "Epoch 93/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1950 - acc: 0.9470     \n",
      "Epoch 94/100\n",
      "3036/3036 [==============================] - ETA: 0s - loss: 0.1978 - acc: 0.945 - 0s - loss: 0.1946 - acc: 0.9470     \n",
      "Epoch 95/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1945 - acc: 0.9470     \n",
      "Epoch 96/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1945 - acc: 0.9470     \n",
      "Epoch 97/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1943 - acc: 0.9470     \n",
      "Epoch 98/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1942 - acc: 0.9470     \n",
      "Epoch 99/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1942 - acc: 0.9470     \n",
      "Epoch 100/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1945 - acc: 0.9470     \n",
      " 32/337 [=>............................] - ETA: 0sEpoch 1/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.6731 - acc: 0.9463     \n",
      "Epoch 2/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.6336 - acc: 0.9486     \n",
      "Epoch 3/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5972 - acc: 0.9486     \n",
      "Epoch 4/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5638 - acc: 0.9486     \n",
      "Epoch 5/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5331 - acc: 0.9486     \n",
      "Epoch 6/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5049 - acc: 0.9486     \n",
      "Epoch 7/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4790 - acc: 0.9486     \n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 0s - loss: 0.4554 - acc: 0.9486     \n",
      "Epoch 9/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4337 - acc: 0.9486     \n",
      "Epoch 10/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4138 - acc: 0.9486     \n",
      "Epoch 11/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3957 - acc: 0.9486     \n",
      "Epoch 12/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3790 - acc: 0.9486     \n",
      "Epoch 13/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3638 - acc: 0.9486     \n",
      "Epoch 14/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3498 - acc: 0.9486     \n",
      "Epoch 15/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3371 - acc: 0.9486     \n",
      "Epoch 16/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3254 - acc: 0.9486     \n",
      "Epoch 17/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3147 - acc: 0.9486     \n",
      "Epoch 18/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3049 - acc: 0.9486     \n",
      "Epoch 19/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2959 - acc: 0.9486     \n",
      "Epoch 20/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2876 - acc: 0.9486     \n",
      "Epoch 21/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2801 - acc: 0.9486     \n",
      "Epoch 22/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2732 - acc: 0.9486     \n",
      "Epoch 23/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2668 - acc: 0.9486     \n",
      "Epoch 24/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2610 - acc: 0.9486     \n",
      "Epoch 25/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2557 - acc: 0.9486     \n",
      "Epoch 26/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2508 - acc: 0.9486     \n",
      "Epoch 27/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2463 - acc: 0.9486     \n",
      "Epoch 28/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2422 - acc: 0.9486     \n",
      "Epoch 29/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2385 - acc: 0.9486     \n",
      "Epoch 30/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2350 - acc: 0.9486     \n",
      "Epoch 31/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2319 - acc: 0.9486     \n",
      "Epoch 32/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2290 - acc: 0.9486     \n",
      "Epoch 33/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2264 - acc: 0.9486     \n",
      "Epoch 34/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2240 - acc: 0.9486     \n",
      "Epoch 35/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2218 - acc: 0.9486     \n",
      "Epoch 36/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2198 - acc: 0.9486     \n",
      "Epoch 37/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2180 - acc: 0.9486     \n",
      "Epoch 38/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2164 - acc: 0.9486     \n",
      "Epoch 39/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2149 - acc: 0.9486     \n",
      "Epoch 40/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2135 - acc: 0.9486     \n",
      "Epoch 41/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2123 - acc: 0.9486     \n",
      "Epoch 42/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2112 - acc: 0.9486     \n",
      "Epoch 43/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2102 - acc: 0.9486     \n",
      "Epoch 44/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2093 - acc: 0.9486     \n",
      "Epoch 45/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2085 - acc: 0.9486     \n",
      "Epoch 46/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2078 - acc: 0.9486     \n",
      "Epoch 47/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2071 - acc: 0.9486     \n",
      "Epoch 48/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2066 - acc: 0.9486     \n",
      "Epoch 49/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2060 - acc: 0.9486     \n",
      "Epoch 50/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2056 - acc: 0.9486     \n",
      "Epoch 51/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2052 - acc: 0.9486     \n",
      "Epoch 52/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2048 - acc: 0.9486     \n",
      "Epoch 53/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9486     \n",
      "Epoch 54/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2042 - acc: 0.9486     \n",
      "Epoch 55/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2040 - acc: 0.9486     \n",
      "Epoch 56/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2038 - acc: 0.9486     \n",
      "Epoch 57/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2036 - acc: 0.9486     \n",
      "Epoch 58/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2034 - acc: 0.9486     \n",
      "Epoch 59/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2033 - acc: 0.9486     \n",
      "Epoch 60/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2032 - acc: 0.9486     \n",
      "Epoch 61/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2031 - acc: 0.9486     \n",
      "Epoch 62/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2030 - acc: 0.9486     \n",
      "Epoch 63/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2029 - acc: 0.9486     \n",
      "Epoch 64/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2029 - acc: 0.9486     \n",
      "Epoch 65/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2028 - acc: 0.9486     \n",
      "Epoch 66/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2028 - acc: 0.9486     \n",
      "Epoch 67/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2027 - acc: 0.9486     \n",
      "Epoch 68/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2027 - acc: 0.9486     \n",
      "Epoch 69/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2027 - acc: 0.9486     \n",
      "Epoch 70/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2027 - acc: 0.9486     \n",
      "Epoch 71/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2027 - acc: 0.9486     \n",
      "Epoch 72/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 73/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 74/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 75/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 76/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 77/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 78/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 79/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 80/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 81/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 82/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 83/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 84/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 85/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 86/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 87/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 88/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 89/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 90/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 91/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 92/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 93/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 95/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 96/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 97/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 98/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 99/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      "Epoch 100/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9486     \n",
      " 32/337 [=>............................] - ETA: 1sEpoch 1/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.6728 - acc: 0.9394     \n",
      "Epoch 2/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.6332 - acc: 0.9480     \n",
      "Epoch 3/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5970 - acc: 0.9480     \n",
      "Epoch 4/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5636 - acc: 0.9480     \n",
      "Epoch 5/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5330 - acc: 0.9480     \n",
      "Epoch 6/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5049 - acc: 0.9480     \n",
      "Epoch 7/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4792 - acc: 0.9480     \n",
      "Epoch 8/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4556 - acc: 0.9480     \n",
      "Epoch 9/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4340 - acc: 0.9480     \n",
      "Epoch 10/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4142 - acc: 0.9480     \n",
      "Epoch 11/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3961 - acc: 0.9480     \n",
      "Epoch 12/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3795 - acc: 0.9480     \n",
      "Epoch 13/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3643 - acc: 0.9480     \n",
      "Epoch 14/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3505 - acc: 0.9480     \n",
      "Epoch 15/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3377 - acc: 0.9480     \n",
      "Epoch 16/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3261 - acc: 0.9480     \n",
      "Epoch 17/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3154 - acc: 0.9480     \n",
      "Epoch 18/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3057 - acc: 0.9480     \n",
      "Epoch 19/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2968 - acc: 0.9480     \n",
      "Epoch 20/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2886 - acc: 0.9480     \n",
      "Epoch 21/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2811 - acc: 0.9480     \n",
      "Epoch 22/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2742 - acc: 0.9480     \n",
      "Epoch 23/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2679 - acc: 0.9480     \n",
      "Epoch 24/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2621 - acc: 0.9480     \n",
      "Epoch 25/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2568 - acc: 0.9480     \n",
      "Epoch 26/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2520 - acc: 0.9480     \n",
      "Epoch 27/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2476 - acc: 0.9480     \n",
      "Epoch 28/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2435 - acc: 0.9480     \n",
      "Epoch 29/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2398 - acc: 0.9480     \n",
      "Epoch 30/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2364 - acc: 0.9480     \n",
      "Epoch 31/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2333 - acc: 0.9480     \n",
      "Epoch 32/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2305 - acc: 0.9480     \n",
      "Epoch 33/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2279 - acc: 0.9480     \n",
      "Epoch 34/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2255 - acc: 0.9480     \n",
      "Epoch 35/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2234 - acc: 0.9480     \n",
      "Epoch 36/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2214 - acc: 0.9480     \n",
      "Epoch 37/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2196 - acc: 0.9480     \n",
      "Epoch 38/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2180 - acc: 0.9480     \n",
      "Epoch 39/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2165 - acc: 0.9480     \n",
      "Epoch 40/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2152 - acc: 0.9480     \n",
      "Epoch 41/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2140 - acc: 0.9480     \n",
      "Epoch 42/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2129 - acc: 0.9480     \n",
      "Epoch 43/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2119 - acc: 0.9480     \n",
      "Epoch 44/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2110 - acc: 0.9480     \n",
      "Epoch 45/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2102 - acc: 0.9480     \n",
      "Epoch 46/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2095 - acc: 0.9480     \n",
      "Epoch 47/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2089 - acc: 0.9480     \n",
      "Epoch 48/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2083 - acc: 0.9480     \n",
      "Epoch 49/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2078 - acc: 0.9480     \n",
      "Epoch 50/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2074 - acc: 0.9480     \n",
      "Epoch 51/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2070 - acc: 0.9480     \n",
      "Epoch 52/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2067 - acc: 0.9480     \n",
      "Epoch 53/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2063 - acc: 0.9480     \n",
      "Epoch 54/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2061 - acc: 0.9480     \n",
      "Epoch 55/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2058 - acc: 0.9480     \n",
      "Epoch 56/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2056 - acc: 0.9480     \n",
      "Epoch 57/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2055 - acc: 0.9480     \n",
      "Epoch 58/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2053 - acc: 0.9480     \n",
      "Epoch 59/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2052 - acc: 0.9480     \n",
      "Epoch 60/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2051 - acc: 0.9480     \n",
      "Epoch 61/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2050 - acc: 0.9480     \n",
      "Epoch 62/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2049 - acc: 0.9480     \n",
      "Epoch 63/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2048 - acc: 0.9480     \n",
      "Epoch 64/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2048 - acc: 0.9480     \n",
      "Epoch 65/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2047 - acc: 0.9480     \n",
      "Epoch 66/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2047 - acc: 0.9480     \n",
      "Epoch 67/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2047 - acc: 0.9480     \n",
      "Epoch 68/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2046 - acc: 0.9480     \n",
      "Epoch 69/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2046 - acc: 0.9480     \n",
      "Epoch 70/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2046 - acc: 0.9480     \n",
      "Epoch 71/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2046 - acc: 0.9480     \n",
      "Epoch 72/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2046 - acc: 0.9480     \n",
      "Epoch 73/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 74/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 75/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 76/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 77/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 78/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 80/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 81/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 82/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 83/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 84/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 85/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 86/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 87/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 88/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 89/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 90/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 91/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 92/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 93/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 94/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 95/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 96/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 97/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 98/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 99/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      "Epoch 100/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9480     \n",
      " 32/337 [=>............................] - ETA: 1sEpoch 1/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.6666 - acc: 0.9354     \n",
      "Epoch 2/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4660 - acc: 0.9453     \n",
      "Epoch 3/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2220 - acc: 0.9453     \n",
      "Epoch 4/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2085 - acc: 0.9453     \n",
      "Epoch 5/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2084 - acc: 0.9453     \n",
      "Epoch 6/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2082 - acc: 0.9453     \n",
      "Epoch 7/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2079 - acc: 0.9453     \n",
      "Epoch 8/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2081 - acc: 0.9453     \n",
      "Epoch 9/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2076 - acc: 0.9453     \n",
      "Epoch 10/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2081 - acc: 0.9453     \n",
      "Epoch 11/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2077 - acc: 0.9453     \n",
      "Epoch 12/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2074 - acc: 0.9453     \n",
      "Epoch 13/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2072 - acc: 0.9453     \n",
      "Epoch 14/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2071 - acc: 0.9453     \n",
      "Epoch 15/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2068 - acc: 0.9453     \n",
      "Epoch 16/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2069 - acc: 0.9453     \n",
      "Epoch 17/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2066 - acc: 0.9453     \n",
      "Epoch 18/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2062 - acc: 0.9453     \n",
      "Epoch 19/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2064 - acc: 0.9453     \n",
      "Epoch 20/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2061 - acc: 0.9453     \n",
      "Epoch 21/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2060 - acc: 0.9453     \n",
      "Epoch 22/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2057 - acc: 0.9453     \n",
      "Epoch 23/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2056 - acc: 0.9453     \n",
      "Epoch 24/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2055 - acc: 0.9453     \n",
      "Epoch 25/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2051 - acc: 0.9453     \n",
      "Epoch 26/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2051 - acc: 0.9453     \n",
      "Epoch 27/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2050 - acc: 0.9453     \n",
      "Epoch 28/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2051 - acc: 0.9453     \n",
      "Epoch 29/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2046 - acc: 0.9453     \n",
      "Epoch 30/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2045 - acc: 0.9453     \n",
      "Epoch 31/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2042 - acc: 0.9453     \n",
      "Epoch 32/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2042 - acc: 0.9453     \n",
      "Epoch 33/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2039 - acc: 0.9453     \n",
      "Epoch 34/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2042 - acc: 0.9453     \n",
      "Epoch 35/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2037 - acc: 0.9453     \n",
      "Epoch 36/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2038 - acc: 0.9453     \n",
      "Epoch 37/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2030 - acc: 0.9453     \n",
      "Epoch 38/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2040 - acc: 0.9453     \n",
      "Epoch 39/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2033 - acc: 0.9453     \n",
      "Epoch 40/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2029 - acc: 0.9453     \n",
      "Epoch 41/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2028 - acc: 0.9453     \n",
      "Epoch 42/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2027 - acc: 0.9453     \n",
      "Epoch 43/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2024 - acc: 0.9453     \n",
      "Epoch 44/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2023 - acc: 0.9453     \n",
      "Epoch 45/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2023 - acc: 0.9453     \n",
      "Epoch 46/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2018 - acc: 0.9453     \n",
      "Epoch 47/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2020 - acc: 0.9453     \n",
      "Epoch 48/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2018 - acc: 0.9453     \n",
      "Epoch 49/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2016 - acc: 0.9453     \n",
      "Epoch 50/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2012 - acc: 0.9453     \n",
      "Epoch 51/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2012 - acc: 0.9453     \n",
      "Epoch 52/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2013 - acc: 0.9453     \n",
      "Epoch 53/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2014 - acc: 0.9453     \n",
      "Epoch 54/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2009 - acc: 0.9453     \n",
      "Epoch 55/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2011 - acc: 0.9453     \n",
      "Epoch 56/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2004 - acc: 0.9453     \n",
      "Epoch 57/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2004 - acc: 0.9453     \n",
      "Epoch 58/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2001 - acc: 0.9453     \n",
      "Epoch 59/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2002 - acc: 0.9453     \n",
      "Epoch 60/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1997 - acc: 0.9453     \n",
      "Epoch 61/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1996 - acc: 0.9453     \n",
      "Epoch 62/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1995 - acc: 0.9453     \n",
      "Epoch 63/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1991 - acc: 0.9453     \n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 0s - loss: 0.1993 - acc: 0.9453     \n",
      "Epoch 65/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1990 - acc: 0.9453     \n",
      "Epoch 66/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9453     \n",
      "Epoch 67/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9453     \n",
      "Epoch 68/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1986 - acc: 0.9453     \n",
      "Epoch 69/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1990 - acc: 0.9453     \n",
      "Epoch 70/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1982 - acc: 0.9453     \n",
      "Epoch 71/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1981 - acc: 0.9453     \n",
      "Epoch 72/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1979 - acc: 0.9453     \n",
      "Epoch 73/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1978 - acc: 0.9453     \n",
      "Epoch 74/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1975 - acc: 0.9453     \n",
      "Epoch 75/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1973 - acc: 0.9453     \n",
      "Epoch 76/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1973 - acc: 0.9453     \n",
      "Epoch 77/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1971 - acc: 0.9453     \n",
      "Epoch 78/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1968 - acc: 0.9453     \n",
      "Epoch 79/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1968 - acc: 0.9453     \n",
      "Epoch 80/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1965 - acc: 0.9453     \n",
      "Epoch 81/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1963 - acc: 0.9453     \n",
      "Epoch 82/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1964 - acc: 0.9453     \n",
      "Epoch 83/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1962 - acc: 0.9453     \n",
      "Epoch 84/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1956 - acc: 0.9453     \n",
      "Epoch 85/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1957 - acc: 0.9453     \n",
      "Epoch 86/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1955 - acc: 0.9453     \n",
      "Epoch 87/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1952 - acc: 0.9453     \n",
      "Epoch 88/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1951 - acc: 0.9453     \n",
      "Epoch 89/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1953 - acc: 0.9453     \n",
      "Epoch 90/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1947 - acc: 0.9453     \n",
      "Epoch 91/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1944 - acc: 0.9453     \n",
      "Epoch 92/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1945 - acc: 0.9453     \n",
      "Epoch 93/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1941 - acc: 0.9453     \n",
      "Epoch 94/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1936 - acc: 0.9453     \n",
      "Epoch 95/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1934 - acc: 0.9453     \n",
      "Epoch 96/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1929 - acc: 0.9453     \n",
      "Epoch 97/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1928 - acc: 0.9453     \n",
      "Epoch 98/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1925 - acc: 0.9453     \n",
      "Epoch 99/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1926 - acc: 0.9453     \n",
      "Epoch 100/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1919 - acc: 0.9453     \n",
      " 32/337 [=>............................] - ETA: 1sEpoch 1/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.6728 - acc: 0.9407     \n",
      "Epoch 2/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.6330 - acc: 0.9499     \n",
      "Epoch 3/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5965 - acc: 0.9499     \n",
      "Epoch 4/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5630 - acc: 0.9499     \n",
      "Epoch 5/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5322 - acc: 0.9499     \n",
      "Epoch 6/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.5039 - acc: 0.9499     \n",
      "Epoch 7/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4780 - acc: 0.9499     \n",
      "Epoch 8/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4542 - acc: 0.9499     \n",
      "Epoch 9/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4324 - acc: 0.9499     \n",
      "Epoch 10/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4125 - acc: 0.9499     \n",
      "Epoch 11/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3942 - acc: 0.9499     \n",
      "Epoch 12/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3775 - acc: 0.9499     \n",
      "Epoch 13/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3621 - acc: 0.9499     \n",
      "Epoch 14/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3481 - acc: 0.9499     \n",
      "Epoch 15/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3352 - acc: 0.9499     \n",
      "Epoch 16/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3234 - acc: 0.9499     \n",
      "Epoch 17/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3127 - acc: 0.9499     \n",
      "Epoch 18/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.3028 - acc: 0.9499     \n",
      "Epoch 19/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2937 - acc: 0.9499     \n",
      "Epoch 20/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2854 - acc: 0.9499     \n",
      "Epoch 21/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2778 - acc: 0.9499     \n",
      "Epoch 22/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2708 - acc: 0.9499     \n",
      "Epoch 23/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2644 - acc: 0.9499     \n",
      "Epoch 24/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2585 - acc: 0.9499     \n",
      "Epoch 25/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2531 - acc: 0.9499     \n",
      "Epoch 26/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2481 - acc: 0.9499     \n",
      "Epoch 27/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2436 - acc: 0.9499     \n",
      "Epoch 28/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2394 - acc: 0.9499     \n",
      "Epoch 29/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2356 - acc: 0.9499     \n",
      "Epoch 30/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2321 - acc: 0.9499     \n",
      "Epoch 31/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2289 - acc: 0.9499     \n",
      "Epoch 32/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2260 - acc: 0.9499     \n",
      "Epoch 33/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2233 - acc: 0.9499     \n",
      "Epoch 34/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2209 - acc: 0.9499     \n",
      "Epoch 35/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2186 - acc: 0.9499     \n",
      "Epoch 36/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2166 - acc: 0.9499     \n",
      "Epoch 37/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2148 - acc: 0.9499     \n",
      "Epoch 38/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2131 - acc: 0.9499     \n",
      "Epoch 39/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2115 - acc: 0.9499     \n",
      "Epoch 40/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2101 - acc: 0.9499     \n",
      "Epoch 41/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2089 - acc: 0.9499     \n",
      "Epoch 42/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2077 - acc: 0.9499     \n",
      "Epoch 43/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2067 - acc: 0.9499     \n",
      "Epoch 44/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2058 - acc: 0.9499     \n",
      "Epoch 45/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2049 - acc: 0.9499     \n",
      "Epoch 46/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2042 - acc: 0.9499     \n",
      "Epoch 47/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2035 - acc: 0.9499     \n",
      "Epoch 48/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2029 - acc: 0.9499     \n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 0s - loss: 0.2024 - acc: 0.9499     \n",
      "Epoch 50/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2019 - acc: 0.9499     \n",
      "Epoch 51/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2015 - acc: 0.9499     \n",
      "Epoch 52/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2011 - acc: 0.9499     \n",
      "Epoch 53/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2008 - acc: 0.9499     \n",
      "Epoch 54/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2005 - acc: 0.9499     \n",
      "Epoch 55/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2002 - acc: 0.9499     \n",
      "Epoch 56/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2000 - acc: 0.9499     \n",
      "Epoch 57/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1998 - acc: 0.9499     \n",
      "Epoch 58/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1997 - acc: 0.9499     \n",
      "Epoch 59/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1995 - acc: 0.9499     \n",
      "Epoch 60/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1994 - acc: 0.9499     \n",
      "Epoch 61/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1993 - acc: 0.9499     \n",
      "Epoch 62/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1992 - acc: 0.9499     \n",
      "Epoch 63/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1991 - acc: 0.9499     \n",
      "Epoch 64/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1991 - acc: 0.9499     \n",
      "Epoch 65/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1990 - acc: 0.9499     \n",
      "Epoch 66/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1989 - acc: 0.9499     \n",
      "Epoch 67/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1989 - acc: 0.9499     \n",
      "Epoch 68/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1989 - acc: 0.9499     \n",
      "Epoch 69/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1989 - acc: 0.9499     \n",
      "Epoch 70/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9499     \n",
      "Epoch 71/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9499     \n",
      "Epoch 72/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9499     \n",
      "Epoch 73/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9499     \n",
      "Epoch 74/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9499     \n",
      "Epoch 75/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9499     \n",
      "Epoch 76/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1988 - acc: 0.9499     \n",
      "Epoch 77/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 78/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 79/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 80/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 81/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 82/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 83/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 84/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 85/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 86/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 87/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 88/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 89/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 90/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 91/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 92/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 93/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 94/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 95/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 96/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 97/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 98/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 99/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      "Epoch 100/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9499     \n",
      " 32/337 [=>............................] - ETA: 1sEpoch 1/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.6614 - acc: 0.9397     \n",
      "Epoch 2/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.4048 - acc: 0.9470     \n",
      "Epoch 3/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2065 - acc: 0.9470     \n",
      "Epoch 4/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2034 - acc: 0.9470     \n",
      "Epoch 5/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2032 - acc: 0.9470     \n",
      "Epoch 6/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2031 - acc: 0.9470     \n",
      "Epoch 7/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2028 - acc: 0.9470     \n",
      "Epoch 8/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9470     \n",
      "Epoch 9/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2026 - acc: 0.9470     \n",
      "Epoch 10/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2023 - acc: 0.9470     \n",
      "Epoch 11/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2025 - acc: 0.9470     \n",
      "Epoch 12/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2021 - acc: 0.9470     \n",
      "Epoch 13/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2017 - acc: 0.9470     \n",
      "Epoch 14/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2018 - acc: 0.9470     \n",
      "Epoch 15/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2017 - acc: 0.9470     \n",
      "Epoch 16/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2011 - acc: 0.9470     \n",
      "Epoch 17/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2014 - acc: 0.9470     \n",
      "Epoch 18/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2011 - acc: 0.9470     \n",
      "Epoch 19/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2011 - acc: 0.9470     \n",
      "Epoch 20/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2006 - acc: 0.9470     \n",
      "Epoch 21/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2003 - acc: 0.9470     \n",
      "Epoch 22/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2004 - acc: 0.9470     \n",
      "Epoch 23/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2000 - acc: 0.9470     \n",
      "Epoch 24/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2001 - acc: 0.9470     \n",
      "Epoch 25/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.2000 - acc: 0.9470     \n",
      "Epoch 26/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1998 - acc: 0.9470     \n",
      "Epoch 27/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1994 - acc: 0.9470     \n",
      "Epoch 28/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1993 - acc: 0.9470     \n",
      "Epoch 29/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1991 - acc: 0.9470     \n",
      "Epoch 30/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1989 - acc: 0.9470     \n",
      "Epoch 31/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1987 - acc: 0.9470     \n",
      "Epoch 32/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1984 - acc: 0.9470     \n",
      "Epoch 33/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1984 - acc: 0.9470     \n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3036/3036 [==============================] - 0s - loss: 0.1986 - acc: 0.9470     \n",
      "Epoch 35/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1980 - acc: 0.9470     \n",
      "Epoch 36/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1978 - acc: 0.9470     \n",
      "Epoch 37/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1974 - acc: 0.9470     \n",
      "Epoch 38/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1975 - acc: 0.9470     \n",
      "Epoch 39/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1975 - acc: 0.9470     \n",
      "Epoch 40/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1972 - acc: 0.9470     \n",
      "Epoch 41/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1968 - acc: 0.9470     \n",
      "Epoch 42/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1966 - acc: 0.9470     \n",
      "Epoch 43/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1966 - acc: 0.9470     \n",
      "Epoch 44/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1965 - acc: 0.9470     \n",
      "Epoch 45/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1962 - acc: 0.9470     \n",
      "Epoch 46/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1959 - acc: 0.9470     \n",
      "Epoch 47/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1962 - acc: 0.9470     \n",
      "Epoch 48/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1958 - acc: 0.9470     \n",
      "Epoch 49/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1957 - acc: 0.9470     \n",
      "Epoch 50/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1954 - acc: 0.9470     \n",
      "Epoch 51/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1952 - acc: 0.9470     \n",
      "Epoch 52/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1948 - acc: 0.9470     \n",
      "Epoch 53/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1949 - acc: 0.9470     \n",
      "Epoch 54/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1947 - acc: 0.9470     \n",
      "Epoch 55/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1943 - acc: 0.9470     \n",
      "Epoch 56/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1942 - acc: 0.9470     \n",
      "Epoch 57/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1941 - acc: 0.9470     \n",
      "Epoch 58/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1940 - acc: 0.9470     \n",
      "Epoch 59/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1938 - acc: 0.9470     \n",
      "Epoch 60/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1933 - acc: 0.9470     \n",
      "Epoch 61/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1937 - acc: 0.9470     \n",
      "Epoch 62/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1934 - acc: 0.9470     \n",
      "Epoch 63/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1929 - acc: 0.9470     \n",
      "Epoch 64/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1929 - acc: 0.9470     \n",
      "Epoch 65/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1929 - acc: 0.9470     \n",
      "Epoch 66/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1925 - acc: 0.9470     \n",
      "Epoch 67/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1924 - acc: 0.9470     \n",
      "Epoch 68/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1918 - acc: 0.9470     \n",
      "Epoch 69/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1923 - acc: 0.9470     \n",
      "Epoch 70/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1917 - acc: 0.9470     \n",
      "Epoch 71/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1917 - acc: 0.9470     \n",
      "Epoch 72/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1913 - acc: 0.9470     \n",
      "Epoch 73/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1916 - acc: 0.9470     \n",
      "Epoch 74/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1911 - acc: 0.9470     \n",
      "Epoch 75/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1905 - acc: 0.9470     \n",
      "Epoch 76/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1907 - acc: 0.9470     \n",
      "Epoch 77/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1904 - acc: 0.9470     \n",
      "Epoch 78/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1903 - acc: 0.9470     \n",
      "Epoch 79/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1898 - acc: 0.9470     \n",
      "Epoch 80/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1898 - acc: 0.9470     \n",
      "Epoch 81/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1894 - acc: 0.9470     \n",
      "Epoch 82/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1890 - acc: 0.9470     \n",
      "Epoch 83/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1893 - acc: 0.9470     \n",
      "Epoch 84/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1885 - acc: 0.9470     \n",
      "Epoch 85/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1882 - acc: 0.9470     \n",
      "Epoch 86/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1883 - acc: 0.9470     \n",
      "Epoch 87/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1877 - acc: 0.9470     \n",
      "Epoch 88/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1872 - acc: 0.9470     \n",
      "Epoch 89/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1866 - acc: 0.9470     \n",
      "Epoch 90/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1868 - acc: 0.9470     \n",
      "Epoch 91/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1864 - acc: 0.9470     \n",
      "Epoch 92/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1859 - acc: 0.9470     \n",
      "Epoch 93/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1855 - acc: 0.9470     \n",
      "Epoch 94/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1857 - acc: 0.9470     \n",
      "Epoch 95/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1852 - acc: 0.9470     \n",
      "Epoch 96/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1845 - acc: 0.9470     \n",
      "Epoch 97/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1838 - acc: 0.9470     \n",
      "Epoch 98/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1831 - acc: 0.9470     \n",
      "Epoch 99/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1831 - acc: 0.9470     \n",
      "Epoch 100/100\n",
      "3036/3036 [==============================] - 0s - loss: 0.1823 - acc: 0.9470     \n",
      " 32/337 [=>............................] - ETA: 1sAccuracy mean: 0.947818376574\n",
      "Accuracy variance: 0.0125397786431\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 96.957123 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 97.441217 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 97.441217 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 97.510373 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 90.525588 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
