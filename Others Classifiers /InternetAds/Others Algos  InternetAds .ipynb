{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt \n",
    "from pprint import pprint\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>att11</th>\n",
       "      <th>att12</th>\n",
       "      <th>att13</th>\n",
       "      <th>...</th>\n",
       "      <th>att1550</th>\n",
       "      <th>att1551</th>\n",
       "      <th>att1552</th>\n",
       "      <th>att1553</th>\n",
       "      <th>att1554</th>\n",
       "      <th>att1555</th>\n",
       "      <th>att1556</th>\n",
       "      <th>att1557</th>\n",
       "      <th>att1558</th>\n",
       "      <th>outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1556 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   att4  att5  att6  att7  att8  att9  att10  att11  att12  att13   ...     \\\n",
       "0   1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   ...      \n",
       "1   1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   ...      \n",
       "2   1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   ...      \n",
       "3   1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   ...      \n",
       "4   1.0   0.0   0.0   0.0   0.0   0.0    0.0    0.0    0.0    0.0   ...      \n",
       "\n",
       "   att1550  att1551  att1552  att1553  att1554  att1555  att1556  att1557  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   att1558  outlier  \n",
       "0      0.0        1  \n",
       "1      0.0        1  \n",
       "2      0.0        1  \n",
       "3      0.0        1  \n",
       "4      0.0        1  \n",
       "\n",
       "[5 rows x 1556 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df=pd.read_csv('InternetAds_norm_19.csv')  \n",
    "\n",
    "del df['id']\n",
    "del df['Unnamed: 0']\n",
    "df['outlier'] = df.outlier.apply(lambda label: 1 if label == \"'yes'\" else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df to values\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GC Forest\n",
    "import argparse\n",
    "import sys\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.insert(0, \"lib\")\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.gcforest import GCForest\n",
    "from gcforest.utils.config_utils import load_json\n",
    "config = load_json(\"./examples/InternetAds.json\")   \n",
    "gc = GCForest(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test \n",
    "from sklearn.cross_validation import train_test_split\n",
    "y = df[:,1555]\n",
    "X = df[:,0:1555]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of class\n",
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 19:57:20,239][cascade_classifier.fit_transform] X_groups_train.shape=[(2284, 1555)],y_train.shape=(2284,),X_groups_test.shape=[(980, 1555)],y_test.shape=(980,)\n",
      "[ 2018-04-25 19:57:20,253][cascade_classifier.fit_transform] group_dims=[1555]\n",
      "[ 2018-04-25 19:57:20,254][cascade_classifier.fit_transform] group_starts=[0]\n",
      "[ 2018-04-25 19:57:20,256][cascade_classifier.fit_transform] group_ends=[1555]\n",
      "[ 2018-04-25 19:57:20,257][cascade_classifier.fit_transform] X_train.shape=(2284, 1555),X_test.shape=(980, 1555)\n",
      "[ 2018-04-25 19:57:20,275][cascade_classifier.fit_transform] [layer=0] look_indexs=[0], X_cur_train.shape=(2284, 1555), X_cur_test.shape=(980, 1555)\n",
      "[ 2018-04-25 19:57:21,014][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_0.predict)=93.89%\n",
      "[ 2018-04-25 19:57:21,760][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_1.predict)=96.94%\n",
      "[ 2018-04-25 19:57:22,667][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_2.predict)=98.69%\n",
      "[ 2018-04-25 19:57:23,583][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_3.predict)=96.51%\n",
      "[ 2018-04-25 19:57:24,463][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_4.predict)=96.93%\n",
      "[ 2018-04-25 19:57:25,258][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_5.predict)=97.37%\n",
      "[ 2018-04-25 19:57:26,177][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_6.predict)=97.81%\n",
      "[ 2018-04-25 19:57:27,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_7.predict)=97.81%\n",
      "[ 2018-04-25 19:57:28,016][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_8.predict)=95.61%\n",
      "[ 2018-04-25 19:57:28,998][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_9.predict)=96.05%\n",
      "[ 2018-04-25 19:57:29,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.train_cv.predict)=96.76%\n",
      "[ 2018-04-25 19:57:29,153][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_0 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-04-25 19:57:29,768][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-04-25 19:57:30,624][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_1.predict)=96.94%\n",
      "[ 2018-04-25 19:57:31,567][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_2.predict)=97.82%\n",
      "[ 2018-04-25 19:57:32,461][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_3.predict)=93.89%\n",
      "[ 2018-04-25 19:57:33,431][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_4.predict)=97.37%\n",
      "[ 2018-04-25 19:57:34,190][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_5.predict)=96.05%\n",
      "[ 2018-04-25 19:57:35,066][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_6.predict)=96.05%\n",
      "[ 2018-04-25 19:57:36,002][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-04-25 19:57:36,795][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_8.predict)=97.81%\n",
      "[ 2018-04-25 19:57:37,705][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_9.predict)=95.61%\n",
      "[ 2018-04-25 19:57:37,860][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.train_cv.predict)=96.54%\n",
      "[ 2018-04-25 19:57:37,862][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_1 - 10_folds.test.predict)=97.65%\n",
      "[ 2018-04-25 19:57:37,960][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_0.predict)=96.07%\n",
      "[ 2018-04-25 19:57:38,001][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_1.predict)=97.82%\n",
      "[ 2018-04-25 19:57:38,042][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-04-25 19:57:38,077][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_3.predict)=94.76%\n",
      "[ 2018-04-25 19:57:38,109][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_4.predict)=96.05%\n",
      "[ 2018-04-25 19:57:38,141][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_5.predict)=98.25%\n",
      "[ 2018-04-25 19:57:38,173][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_6.predict)=96.93%\n",
      "[ 2018-04-25 19:57:38,205][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_7.predict)=96.05%\n",
      "[ 2018-04-25 19:57:38,236][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_8.predict)=96.49%\n",
      "[ 2018-04-25 19:57:38,268][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_9.predict)=96.93%\n",
      "[ 2018-04-25 19:57:38,274][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.train_cv.predict)=96.63%\n",
      "[ 2018-04-25 19:57:38,277][kfold_wrapper.log_eval_metrics] Accuracy(layer_0 - estimator_2 - 10_folds.test.predict)=97.45%\n",
      "[ 2018-04-25 19:57:38,279][cascade_classifier.calc_accuracy] Accuracy(layer_0 - train.classifier_average)=96.94%\n",
      "[ 2018-04-25 19:57:38,281][cascade_classifier.calc_accuracy] Accuracy(layer_0 - test.classifier_average)=97.76%\n",
      "[ 2018-04-25 19:57:38,311][cascade_classifier.fit_transform] [layer=1] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 19:57:39,091][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_0.predict)=96.07%\n",
      "[ 2018-04-25 19:57:39,880][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_1.predict)=98.69%\n",
      "[ 2018-04-25 19:57:40,810][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_2.predict)=98.25%\n",
      "[ 2018-04-25 19:57:41,619][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_3.predict)=96.94%\n",
      "[ 2018-04-25 19:57:42,417][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_4.predict)=97.37%\n",
      "[ 2018-04-25 19:57:43,227][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_5.predict)=96.93%\n",
      "[ 2018-04-25 19:57:43,997][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_6.predict)=99.56%\n",
      "[ 2018-04-25 19:57:45,021][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_7.predict)=97.81%\n",
      "[ 2018-04-25 19:57:45,991][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_8.predict)=95.61%\n",
      "[ 2018-04-25 19:57:46,834][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_9.predict)=96.49%\n",
      "[ 2018-04-25 19:57:46,988][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.train_cv.predict)=97.37%\n",
      "[ 2018-04-25 19:57:46,990][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_0 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-04-25 19:57:47,617][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_0.predict)=97.82%\n",
      "[ 2018-04-25 19:57:48,378][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_1.predict)=96.94%\n",
      "[ 2018-04-25 19:57:49,241][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-04-25 19:57:50,098][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_3.predict)=97.38%\n",
      "[ 2018-04-25 19:57:50,889][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_4.predict)=97.37%\n",
      "[ 2018-04-25 19:57:51,665][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_5.predict)=97.37%\n",
      "[ 2018-04-25 19:57:52,448][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_6.predict)=97.81%\n",
      "[ 2018-04-25 19:57:53,458][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_7.predict)=97.81%\n",
      "[ 2018-04-25 19:57:54,266][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_8.predict)=96.93%\n",
      "[ 2018-04-25 19:57:55,200][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_9.predict)=96.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 19:57:55,365][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.train_cv.predict)=97.33%\n",
      "[ 2018-04-25 19:57:55,367][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_1 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-04-25 19:57:55,422][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_0.predict)=95.63%\n",
      "[ 2018-04-25 19:57:55,468][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_1.predict)=96.07%\n",
      "[ 2018-04-25 19:57:55,514][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_2.predict)=99.13%\n",
      "[ 2018-04-25 19:57:55,552][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_3.predict)=98.25%\n",
      "[ 2018-04-25 19:57:55,586][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_4.predict)=96.49%\n",
      "[ 2018-04-25 19:57:55,619][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_5.predict)=98.25%\n",
      "[ 2018-04-25 19:57:55,648][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_6.predict)=95.61%\n",
      "[ 2018-04-25 19:57:55,676][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_7.predict)=98.25%\n",
      "[ 2018-04-25 19:57:55,704][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_8.predict)=97.37%\n",
      "[ 2018-04-25 19:57:55,732][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_9.predict)=96.05%\n",
      "[ 2018-04-25 19:57:55,736][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.train_cv.predict)=97.11%\n",
      "[ 2018-04-25 19:57:55,737][kfold_wrapper.log_eval_metrics] Accuracy(layer_1 - estimator_2 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-04-25 19:57:55,739][cascade_classifier.calc_accuracy] Accuracy(layer_1 - train.classifier_average)=97.37%\n",
      "[ 2018-04-25 19:57:55,741][cascade_classifier.calc_accuracy] Accuracy(layer_1 - test.classifier_average)=97.96%\n",
      "[ 2018-04-25 19:57:55,936][cascade_classifier.fit_transform] [layer=2] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 19:57:56,528][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-04-25 19:57:57,330][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_1.predict)=97.38%\n",
      "[ 2018-04-25 19:57:58,203][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-04-25 19:57:59,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_3.predict)=97.38%\n",
      "[ 2018-04-25 19:57:59,941][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_4.predict)=98.68%\n",
      "[ 2018-04-25 19:58:00,883][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_5.predict)=96.93%\n",
      "[ 2018-04-25 19:58:01,826][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_6.predict)=95.18%\n",
      "[ 2018-04-25 19:58:02,671][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_7.predict)=94.74%\n",
      "[ 2018-04-25 19:58:03,537][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_8.predict)=98.25%\n",
      "[ 2018-04-25 19:58:04,512][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_9.predict)=98.68%\n",
      "[ 2018-04-25 19:58:04,749][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.train_cv.predict)=97.11%\n",
      "[ 2018-04-25 19:58:04,751][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_0 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-04-25 19:58:05,377][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_0.predict)=97.82%\n",
      "[ 2018-04-25 19:58:06,161][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_1.predict)=98.69%\n",
      "[ 2018-04-25 19:58:06,982][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_2.predict)=96.07%\n",
      "[ 2018-04-25 19:58:07,894][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_3.predict)=97.82%\n",
      "[ 2018-04-25 19:58:08,688][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_4.predict)=96.49%\n",
      "[ 2018-04-25 19:58:09,435][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_5.predict)=98.25%\n",
      "[ 2018-04-25 19:58:10,312][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_6.predict)=98.25%\n",
      "[ 2018-04-25 19:58:11,134][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_7.predict)=97.37%\n",
      "[ 2018-04-25 19:58:12,033][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_8.predict)=97.37%\n",
      "[ 2018-04-25 19:58:12,795][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_9.predict)=95.18%\n",
      "[ 2018-04-25 19:58:12,940][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.train_cv.predict)=97.33%\n",
      "[ 2018-04-25 19:58:12,942][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_1 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-04-25 19:58:12,985][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_0.predict)=96.51%\n",
      "[ 2018-04-25 19:58:13,022][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_1.predict)=96.51%\n",
      "[ 2018-04-25 19:58:13,054][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_2.predict)=98.25%\n",
      "[ 2018-04-25 19:58:13,082][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_3.predict)=97.82%\n",
      "[ 2018-04-25 19:58:13,109][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_4.predict)=95.61%\n",
      "[ 2018-04-25 19:58:13,136][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_5.predict)=97.81%\n",
      "[ 2018-04-25 19:58:13,164][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_6.predict)=96.05%\n",
      "[ 2018-04-25 19:58:13,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_7.predict)=97.81%\n",
      "[ 2018-04-25 19:58:13,220][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_8.predict)=96.93%\n",
      "[ 2018-04-25 19:58:13,248][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_9.predict)=98.68%\n",
      "[ 2018-04-25 19:58:13,251][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.train_cv.predict)=97.20%\n",
      "[ 2018-04-25 19:58:13,253][kfold_wrapper.log_eval_metrics] Accuracy(layer_2 - estimator_2 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-04-25 19:58:13,254][cascade_classifier.calc_accuracy] Accuracy(layer_2 - train.classifier_average)=97.37%\n",
      "[ 2018-04-25 19:58:13,256][cascade_classifier.calc_accuracy] Accuracy(layer_2 - test.classifier_average)=97.96%\n",
      "[ 2018-04-25 19:58:13,341][cascade_classifier.fit_transform] [layer=3] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 19:58:13,951][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_0.predict)=95.63%\n",
      "[ 2018-04-25 19:58:14,765][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_1.predict)=97.82%\n",
      "[ 2018-04-25 19:58:15,631][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-04-25 19:58:16,416][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_3.predict)=96.51%\n",
      "[ 2018-04-25 19:58:17,223][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_4.predict)=98.68%\n",
      "[ 2018-04-25 19:58:18,017][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_5.predict)=97.81%\n",
      "[ 2018-04-25 19:58:19,012][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-04-25 19:58:20,003][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-04-25 19:58:20,873][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_8.predict)=95.61%\n",
      "[ 2018-04-25 19:58:21,801][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_9.predict)=97.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 19:58:21,966][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.train_cv.predict)=97.11%\n",
      "[ 2018-04-25 19:58:21,968][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_0 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-04-25 19:58:22,796][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_0.predict)=98.25%\n",
      "[ 2018-04-25 19:58:23,588][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_1.predict)=95.20%\n",
      "[ 2018-04-25 19:58:24,361][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_2.predict)=95.20%\n",
      "[ 2018-04-25 19:58:25,297][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_3.predict)=96.94%\n",
      "[ 2018-04-25 19:58:26,121][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_4.predict)=98.68%\n",
      "[ 2018-04-25 19:58:26,871][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_5.predict)=98.25%\n",
      "[ 2018-04-25 19:58:27,657][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_6.predict)=96.93%\n",
      "[ 2018-04-25 19:58:28,591][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-04-25 19:58:29,396][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_8.predict)=96.93%\n",
      "[ 2018-04-25 19:58:30,215][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_9.predict)=97.81%\n",
      "[ 2018-04-25 19:58:30,372][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.train_cv.predict)=97.11%\n",
      "[ 2018-04-25 19:58:30,374][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_1 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-04-25 19:58:30,426][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_0.predict)=97.82%\n",
      "[ 2018-04-25 19:58:30,484][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_1.predict)=96.94%\n",
      "[ 2018-04-25 19:58:30,622][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_2.predict)=98.25%\n",
      "[ 2018-04-25 19:58:30,661][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_3.predict)=98.69%\n",
      "[ 2018-04-25 19:58:30,696][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_4.predict)=93.86%\n",
      "[ 2018-04-25 19:58:30,727][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_5.predict)=98.25%\n",
      "[ 2018-04-25 19:58:30,757][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_6.predict)=94.30%\n",
      "[ 2018-04-25 19:58:30,788][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_7.predict)=97.37%\n",
      "[ 2018-04-25 19:58:30,817][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_8.predict)=98.68%\n",
      "[ 2018-04-25 19:58:30,847][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_9.predict)=96.93%\n",
      "[ 2018-04-25 19:58:30,851][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.train_cv.predict)=97.11%\n",
      "[ 2018-04-25 19:58:30,852][kfold_wrapper.log_eval_metrics] Accuracy(layer_3 - estimator_2 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-04-25 19:58:30,854][cascade_classifier.calc_accuracy] Accuracy(layer_3 - train.classifier_average)=97.29%\n",
      "[ 2018-04-25 19:58:30,856][cascade_classifier.calc_accuracy] Accuracy(layer_3 - test.classifier_average)=97.96%\n",
      "[ 2018-04-25 19:58:30,871][cascade_classifier.fit_transform] [layer=4] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 19:58:31,520][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_0.predict)=98.69%\n",
      "[ 2018-04-25 19:58:32,307][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_1.predict)=97.38%\n",
      "[ 2018-04-25 19:58:33,132][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_2.predict)=96.51%\n",
      "[ 2018-04-25 19:58:33,939][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_3.predict)=95.63%\n",
      "[ 2018-04-25 19:58:34,709][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_4.predict)=99.12%\n",
      "[ 2018-04-25 19:58:35,542][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_5.predict)=96.49%\n",
      "[ 2018-04-25 19:58:36,476][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_6.predict)=98.25%\n",
      "[ 2018-04-25 19:58:37,376][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_7.predict)=96.05%\n",
      "[ 2018-04-25 19:58:38,167][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_8.predict)=96.93%\n",
      "[ 2018-04-25 19:58:38,976][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_9.predict)=97.81%\n",
      "[ 2018-04-25 19:58:39,126][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.train_cv.predict)=97.29%\n",
      "[ 2018-04-25 19:58:39,128][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_0 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-04-25 19:58:39,895][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_0.predict)=97.82%\n",
      "[ 2018-04-25 19:58:40,678][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_1.predict)=96.94%\n",
      "[ 2018-04-25 19:58:41,513][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_2.predict)=96.07%\n",
      "[ 2018-04-25 19:58:42,399][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_3.predict)=96.94%\n",
      "[ 2018-04-25 19:58:43,323][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_4.predict)=97.37%\n",
      "[ 2018-04-25 19:58:44,105][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_5.predict)=97.37%\n",
      "[ 2018-04-25 19:58:44,927][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_6.predict)=98.68%\n",
      "[ 2018-04-25 19:58:45,701][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-04-25 19:58:46,502][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_8.predict)=94.74%\n",
      "[ 2018-04-25 19:58:47,377][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_9.predict)=99.12%\n",
      "[ 2018-04-25 19:58:47,535][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.train_cv.predict)=97.20%\n",
      "[ 2018-04-25 19:58:47,537][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_1 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-04-25 19:58:47,590][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_0.predict)=96.07%\n",
      "[ 2018-04-25 19:58:47,637][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_1.predict)=98.69%\n",
      "[ 2018-04-25 19:58:47,676][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-04-25 19:58:47,708][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_3.predict)=97.82%\n",
      "[ 2018-04-25 19:58:47,737][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_4.predict)=95.18%\n",
      "[ 2018-04-25 19:58:47,766][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_5.predict)=97.37%\n",
      "[ 2018-04-25 19:58:47,795][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_6.predict)=98.25%\n",
      "[ 2018-04-25 19:58:47,823][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-04-25 19:58:47,852][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_8.predict)=96.05%\n",
      "[ 2018-04-25 19:58:47,882][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_9.predict)=97.81%\n",
      "[ 2018-04-25 19:58:47,885][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.train_cv.predict)=97.11%\n",
      "[ 2018-04-25 19:58:47,887][kfold_wrapper.log_eval_metrics] Accuracy(layer_4 - estimator_2 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-04-25 19:58:47,888][cascade_classifier.calc_accuracy] Accuracy(layer_4 - train.classifier_average)=97.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 19:58:47,890][cascade_classifier.calc_accuracy] Accuracy(layer_4 - test.classifier_average)=97.96%\n",
      "[ 2018-04-25 19:58:47,908][cascade_classifier.fit_transform] [layer=5] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 19:58:48,518][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-04-25 19:58:49,368][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_1.predict)=98.69%\n",
      "[ 2018-04-25 19:58:50,141][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_2.predict)=97.82%\n",
      "[ 2018-04-25 19:58:50,963][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_3.predict)=98.25%\n",
      "[ 2018-04-25 19:58:51,737][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_4.predict)=97.81%\n",
      "[ 2018-04-25 19:58:52,604][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_5.predict)=96.93%\n",
      "[ 2018-04-25 19:58:53,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-04-25 19:58:54,172][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_7.predict)=96.05%\n",
      "[ 2018-04-25 19:58:54,968][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_8.predict)=97.81%\n",
      "[ 2018-04-25 19:58:55,768][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_9.predict)=96.05%\n",
      "[ 2018-04-25 19:58:55,925][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.train_cv.predict)=97.37%\n",
      "[ 2018-04-25 19:58:55,927][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_0 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-04-25 19:58:56,544][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_0.predict)=98.25%\n",
      "[ 2018-04-25 19:58:57,368][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_1.predict)=97.38%\n",
      "[ 2018-04-25 19:58:58,186][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_2.predict)=98.69%\n",
      "[ 2018-04-25 19:58:59,006][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_3.predict)=99.13%\n",
      "[ 2018-04-25 19:58:59,771][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_4.predict)=98.25%\n",
      "[ 2018-04-25 19:59:00,604][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_5.predict)=95.61%\n",
      "[ 2018-04-25 19:59:01,404][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_6.predict)=98.25%\n",
      "[ 2018-04-25 19:59:02,343][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_7.predict)=93.86%\n",
      "[ 2018-04-25 19:59:03,110][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_8.predict)=96.49%\n",
      "[ 2018-04-25 19:59:03,897][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_9.predict)=97.37%\n",
      "[ 2018-04-25 19:59:04,050][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.train_cv.predict)=97.33%\n",
      "[ 2018-04-25 19:59:04,052][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_1 - 10_folds.test.predict)=98.06%\n",
      "[ 2018-04-25 19:59:04,100][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_0.predict)=97.38%\n",
      "[ 2018-04-25 19:59:04,151][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_1.predict)=96.94%\n",
      "[ 2018-04-25 19:59:04,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_2.predict)=94.32%\n",
      "[ 2018-04-25 19:59:04,241][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_3.predict)=98.25%\n",
      "[ 2018-04-25 19:59:04,282][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_4.predict)=97.81%\n",
      "[ 2018-04-25 19:59:04,317][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_5.predict)=98.25%\n",
      "[ 2018-04-25 19:59:04,351][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_6.predict)=96.93%\n",
      "[ 2018-04-25 19:59:04,399][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_7.predict)=97.37%\n",
      "[ 2018-04-25 19:59:04,441][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_8.predict)=98.25%\n",
      "[ 2018-04-25 19:59:04,477][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_9.predict)=98.25%\n",
      "[ 2018-04-25 19:59:04,482][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.train_cv.predict)=97.37%\n",
      "[ 2018-04-25 19:59:04,483][kfold_wrapper.log_eval_metrics] Accuracy(layer_5 - estimator_2 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-04-25 19:59:04,485][cascade_classifier.calc_accuracy] Accuracy(layer_5 - train.classifier_average)=97.46%\n",
      "[ 2018-04-25 19:59:04,486][cascade_classifier.calc_accuracy] Accuracy(layer_5 - test.classifier_average)=97.96%\n",
      "[ 2018-04-25 19:59:04,503][cascade_classifier.fit_transform] [layer=6] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 19:59:05,114][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_0.predict)=97.38%\n",
      "[ 2018-04-25 19:59:05,915][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_1.predict)=95.20%\n",
      "[ 2018-04-25 19:59:06,734][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_2.predict)=97.82%\n",
      "[ 2018-04-25 19:59:07,685][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_3.predict)=98.69%\n",
      "[ 2018-04-25 19:59:08,569][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_4.predict)=97.81%\n",
      "[ 2018-04-25 19:59:09,382][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_5.predict)=96.05%\n",
      "[ 2018-04-25 19:59:10,179][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_6.predict)=98.68%\n",
      "[ 2018-04-25 19:59:11,116][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_7.predict)=97.81%\n",
      "[ 2018-04-25 19:59:12,068][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_8.predict)=98.25%\n",
      "[ 2018-04-25 19:59:12,995][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_9.predict)=96.05%\n",
      "[ 2018-04-25 19:59:13,236][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.train_cv.predict)=97.37%\n",
      "[ 2018-04-25 19:59:13,239][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_0 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-04-25 19:59:13,869][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_0.predict)=96.51%\n",
      "[ 2018-04-25 19:59:14,840][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_1.predict)=96.94%\n",
      "[ 2018-04-25 19:59:15,715][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_2.predict)=98.69%\n",
      "[ 2018-04-25 19:59:16,493][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_3.predict)=97.82%\n",
      "[ 2018-04-25 19:59:17,265][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_4.predict)=97.37%\n",
      "[ 2018-04-25 19:59:18,066][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_5.predict)=96.49%\n",
      "[ 2018-04-25 19:59:19,080][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-04-25 19:59:19,876][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_7.predict)=97.81%\n",
      "[ 2018-04-25 19:59:20,628][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_8.predict)=97.37%\n",
      "[ 2018-04-25 19:59:21,548][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_9.predict)=95.61%\n",
      "[ 2018-04-25 19:59:21,704][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.train_cv.predict)=97.20%\n",
      "[ 2018-04-25 19:59:21,706][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_1 - 10_folds.test.predict)=97.76%\n",
      "[ 2018-04-25 19:59:21,760][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_0.predict)=96.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 19:59:21,812][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_1.predict)=96.94%\n",
      "[ 2018-04-25 19:59:21,854][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_2.predict)=98.25%\n",
      "[ 2018-04-25 19:59:21,892][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_3.predict)=95.63%\n",
      "[ 2018-04-25 19:59:21,926][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_4.predict)=96.93%\n",
      "[ 2018-04-25 19:59:21,957][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_5.predict)=99.12%\n",
      "[ 2018-04-25 19:59:21,987][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_6.predict)=96.93%\n",
      "[ 2018-04-25 19:59:22,017][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_7.predict)=98.25%\n",
      "[ 2018-04-25 19:59:22,047][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_8.predict)=98.25%\n",
      "[ 2018-04-25 19:59:22,077][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_9.predict)=96.05%\n",
      "[ 2018-04-25 19:59:22,081][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.train_cv.predict)=97.33%\n",
      "[ 2018-04-25 19:59:22,082][kfold_wrapper.log_eval_metrics] Accuracy(layer_6 - estimator_2 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-04-25 19:59:22,084][cascade_classifier.calc_accuracy] Accuracy(layer_6 - train.classifier_average)=97.37%\n",
      "[ 2018-04-25 19:59:22,085][cascade_classifier.calc_accuracy] Accuracy(layer_6 - test.classifier_average)=97.96%\n",
      "[ 2018-04-25 19:59:22,102][cascade_classifier.fit_transform] [layer=7] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 19:59:22,694][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_0.predict)=96.07%\n",
      "[ 2018-04-25 19:59:23,540][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_1.predict)=96.07%\n",
      "[ 2018-04-25 19:59:24,400][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_2.predict)=97.38%\n",
      "[ 2018-04-25 19:59:25,212][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_3.predict)=96.51%\n",
      "[ 2018-04-25 19:59:26,015][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_4.predict)=98.25%\n",
      "[ 2018-04-25 19:59:26,832][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_5.predict)=97.81%\n",
      "[ 2018-04-25 19:59:27,632][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_6.predict)=97.81%\n",
      "[ 2018-04-25 19:59:28,396][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_7.predict)=98.25%\n",
      "[ 2018-04-25 19:59:29,222][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_8.predict)=98.68%\n",
      "[ 2018-04-25 19:59:30,016][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_9.predict)=96.49%\n",
      "[ 2018-04-25 19:59:30,167][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.train_cv.predict)=97.33%\n",
      "[ 2018-04-25 19:59:30,169][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_0 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-04-25 19:59:30,795][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_0.predict)=96.51%\n",
      "[ 2018-04-25 19:59:31,588][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_1.predict)=98.69%\n",
      "[ 2018-04-25 19:59:32,368][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_2.predict)=96.51%\n",
      "[ 2018-04-25 19:59:33,145][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_3.predict)=99.13%\n",
      "[ 2018-04-25 19:59:33,955][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_4.predict)=96.93%\n",
      "[ 2018-04-25 19:59:34,786][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_5.predict)=95.61%\n",
      "[ 2018-04-25 19:59:35,572][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_6.predict)=94.30%\n",
      "[ 2018-04-25 19:59:36,356][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_7.predict)=97.81%\n",
      "[ 2018-04-25 19:59:37,291][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_8.predict)=96.49%\n",
      "[ 2018-04-25 19:59:38,094][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_9.predict)=97.81%\n",
      "[ 2018-04-25 19:59:38,238][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.train_cv.predict)=96.98%\n",
      "[ 2018-04-25 19:59:38,240][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_1 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-04-25 19:59:38,286][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_0.predict)=97.38%\n",
      "[ 2018-04-25 19:59:38,325][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_1.predict)=97.82%\n",
      "[ 2018-04-25 19:59:38,362][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_2.predict)=98.25%\n",
      "[ 2018-04-25 19:59:38,398][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_3.predict)=98.25%\n",
      "[ 2018-04-25 19:59:38,428][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_4.predict)=98.25%\n",
      "[ 2018-04-25 19:59:38,456][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_5.predict)=95.61%\n",
      "[ 2018-04-25 19:59:38,485][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-04-25 19:59:38,514][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-04-25 19:59:38,544][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_8.predict)=96.05%\n",
      "[ 2018-04-25 19:59:38,573][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_9.predict)=97.37%\n",
      "[ 2018-04-25 19:59:38,576][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.train_cv.predict)=97.33%\n",
      "[ 2018-04-25 19:59:38,577][kfold_wrapper.log_eval_metrics] Accuracy(layer_7 - estimator_2 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-04-25 19:59:38,579][cascade_classifier.calc_accuracy] Accuracy(layer_7 - train.classifier_average)=97.29%\n",
      "[ 2018-04-25 19:59:38,580][cascade_classifier.calc_accuracy] Accuracy(layer_7 - test.classifier_average)=97.96%\n",
      "[ 2018-04-25 19:59:38,598][cascade_classifier.fit_transform] [layer=8] look_indexs=[0], X_cur_train.shape=(2284, 1561), X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 19:59:39,311][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_0.predict)=96.94%\n",
      "[ 2018-04-25 19:59:40,108][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_1.predict)=99.13%\n",
      "[ 2018-04-25 19:59:40,897][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_2.predict)=97.82%\n",
      "[ 2018-04-25 19:59:41,695][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_3.predict)=96.07%\n",
      "[ 2018-04-25 19:59:42,463][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_4.predict)=98.25%\n",
      "[ 2018-04-25 19:59:43,261][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_5.predict)=98.68%\n",
      "[ 2018-04-25 19:59:44,069][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_6.predict)=97.37%\n",
      "[ 2018-04-25 19:59:44,893][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_7.predict)=97.37%\n",
      "[ 2018-04-25 19:59:45,656][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_8.predict)=95.61%\n",
      "[ 2018-04-25 19:59:46,480][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_9.predict)=94.74%\n",
      "[ 2018-04-25 19:59:46,634][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.train_cv.predict)=97.20%\n",
      "[ 2018-04-25 19:59:46,636][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_0 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-04-25 19:59:47,256][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_0.predict)=96.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 19:59:48,048][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_1.predict)=96.51%\n",
      "[ 2018-04-25 19:59:48,838][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_2.predict)=96.07%\n",
      "[ 2018-04-25 19:59:49,679][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_3.predict)=95.63%\n",
      "[ 2018-04-25 19:59:50,514][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_4.predict)=98.25%\n",
      "[ 2018-04-25 19:59:51,429][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_5.predict)=98.68%\n",
      "[ 2018-04-25 19:59:52,192][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_6.predict)=96.93%\n",
      "[ 2018-04-25 19:59:52,934][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_7.predict)=98.25%\n",
      "[ 2018-04-25 19:59:53,761][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_8.predict)=97.81%\n",
      "[ 2018-04-25 19:59:54,618][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_9.predict)=98.25%\n",
      "[ 2018-04-25 19:59:54,770][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.train_cv.predict)=97.33%\n",
      "[ 2018-04-25 19:59:54,772][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_1 - 10_folds.test.predict)=97.86%\n",
      "[ 2018-04-25 19:59:54,830][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_0.predict)=99.13%\n",
      "[ 2018-04-25 19:59:54,887][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_1.predict)=98.69%\n",
      "[ 2018-04-25 19:59:55,019][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_2.predict)=96.94%\n",
      "[ 2018-04-25 19:59:55,059][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_3.predict)=96.94%\n",
      "[ 2018-04-25 19:59:55,099][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_4.predict)=95.18%\n",
      "[ 2018-04-25 19:59:55,138][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_5.predict)=97.81%\n",
      "[ 2018-04-25 19:59:55,178][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_6.predict)=97.81%\n",
      "[ 2018-04-25 19:59:55,216][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_7.predict)=96.93%\n",
      "[ 2018-04-25 19:59:55,253][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_8.predict)=94.74%\n",
      "[ 2018-04-25 19:59:55,289][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_9.predict)=98.25%\n",
      "[ 2018-04-25 19:59:55,292][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.train_cv.predict)=97.24%\n",
      "[ 2018-04-25 19:59:55,294][kfold_wrapper.log_eval_metrics] Accuracy(layer_8 - estimator_2 - 10_folds.test.predict)=97.96%\n",
      "[ 2018-04-25 19:59:55,297][cascade_classifier.calc_accuracy] Accuracy(layer_8 - train.classifier_average)=97.29%\n",
      "[ 2018-04-25 19:59:55,299][cascade_classifier.calc_accuracy] Accuracy(layer_8 - test.classifier_average)=97.86%\n",
      "[ 2018-04-25 19:59:55,302][cascade_classifier.fit_transform] [Result][Optimal Level Detected] opt_layer_num=6, accuracy_train=97.46%, accuracy_test=97.96%\n"
     ]
    }
   ],
   "source": [
    "    # X_enc is the concatenated predict_proba result of each estimators of the last layer of the GCForest model\n",
    "    # X_enc.shape =\n",
    "    #   (n_datas, n_estimators * n_classes): If cascade is provided\n",
    "    #   (n_datas, n_estimators * n_classes, dimX, dimY): If only finegrained part is provided\n",
    "    # You can also pass X_test, y_test to fit_transform method, then the accracy on test data will be logged when training.\n",
    "X_train_enc, X_test_enc = gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test)\n",
    "    # WARNING: if you set gc.set_keep_model_in_mem(True), you would have to use\n",
    "    # gc.fit_transform(X_train, y_train, X_test=X_test, y_test=y_test) to evaluate your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ 2018-04-25 19:59:55,376][cascade_classifier.transform] X_groups_test.shape=[(980, 1555)]\n",
      "[ 2018-04-25 19:59:55,495][cascade_classifier.transform] group_dims=[1555]\n",
      "[ 2018-04-25 19:59:55,496][cascade_classifier.transform] X_test.shape=(980, 1555)\n",
      "[ 2018-04-25 19:59:55,502][cascade_classifier.transform] [layer=0] look_indexs=[0], X_cur_test.shape=(980, 1555)\n",
      "[ 2018-04-25 19:59:58,693][cascade_classifier.transform] [layer=1] look_indexs=[0], X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 20:00:01,823][cascade_classifier.transform] [layer=2] look_indexs=[0], X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 20:00:05,104][cascade_classifier.transform] [layer=3] look_indexs=[0], X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 20:00:08,302][cascade_classifier.transform] [layer=4] look_indexs=[0], X_cur_test.shape=(980, 1561)\n",
      "[ 2018-04-25 20:00:11,532][cascade_classifier.transform] [layer=5] look_indexs=[0], X_cur_test.shape=(980, 1561)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GCForest = 97.959184 %\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = gc.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of GCForest = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DecisionTreeClassifier = 96.734694 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of DecisionTreeClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of RandomForestClassifier = 97.653061 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of RandomForestClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of ExtraTreesClassifier = 97.551020 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "clf = ExtraTreesClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of ExtraTreesClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of AdaBoostClassifier = 97.142857 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of AdaBoostClassifier = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Naive_bayes  GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of GaussianNB = 78.061224 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred= gnb.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Test Accuracy of GaussianNB = {:.6f} %\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.6789 - acc: 0.8526     \n",
      "Epoch 2/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.5485 - acc: 0.8564     \n",
      "Epoch 3/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.2674 - acc: 0.9270     \n",
      "Epoch 4/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.1649 - acc: 0.9601     \n",
      "Epoch 5/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.1200 - acc: 0.9684     \n",
      "Epoch 6/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0983 - acc: 0.9742     \n",
      "Epoch 7/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0865 - acc: 0.9771     \n",
      "Epoch 8/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0777 - acc: 0.9786     \n",
      "Epoch 9/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0716 - acc: 0.9800     \n",
      "Epoch 10/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0670 - acc: 0.9796     \n",
      "Epoch 11/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0628 - acc: 0.9820     \n",
      "Epoch 12/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0599 - acc: 0.9830     \n",
      "Epoch 13/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0566 - acc: 0.9830     \n",
      "Epoch 14/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0539 - acc: 0.9839     \n",
      "Epoch 15/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0516 - acc: 0.9854     \n",
      "Epoch 16/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0486 - acc: 0.9864     \n",
      "Epoch 17/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0477 - acc: 0.9859     \n",
      "Epoch 18/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0457 - acc: 0.9878     \n",
      "Epoch 19/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0442 - acc: 0.9869     \n",
      "Epoch 20/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0441 - acc: 0.9878     \n",
      "Epoch 21/100\n",
      "  32/2055 [..............................] - ETA: 0s - loss: 0.0079 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.152045). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 [==============================] - 0s - loss: 0.0431 - acc: 0.9869     \n",
      "Epoch 22/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0416 - acc: 0.9878     \n",
      "Epoch 23/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0401 - acc: 0.9888     \n",
      "Epoch 24/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0391 - acc: 0.9883     \n",
      "Epoch 25/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0383 - acc: 0.9883     \n",
      "Epoch 26/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0374 - acc: 0.9893     \n",
      "Epoch 27/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0365 - acc: 0.9888     \n",
      "Epoch 28/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0354 - acc: 0.9888     \n",
      "Epoch 29/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0350 - acc: 0.9893     \n",
      "Epoch 30/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0340 - acc: 0.9893     \n",
      "Epoch 31/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0336 - acc: 0.9898     \n",
      "Epoch 32/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0335 - acc: 0.9903     \n",
      "Epoch 33/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0327 - acc: 0.9903     \n",
      "Epoch 34/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0322 - acc: 0.9922     \n",
      "Epoch 35/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0312 - acc: 0.9908     \n",
      "Epoch 36/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0313 - acc: 0.9912     \n",
      "Epoch 37/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0315 - acc: 0.9912     \n",
      "Epoch 38/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0309 - acc: 0.9912     \n",
      "Epoch 39/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0307 - acc: 0.9903     \n",
      "Epoch 40/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0304 - acc: 0.9912     \n",
      "Epoch 41/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0298 - acc: 0.9917     \n",
      "Epoch 42/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0297 - acc: 0.9912     \n",
      "Epoch 43/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0296 - acc: 0.9908     \n",
      "Epoch 44/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0305 - acc: 0.9898     \n",
      "Epoch 45/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0292 - acc: 0.9912     \n",
      "Epoch 46/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0287 - acc: 0.9908     \n",
      "Epoch 47/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0298 - acc: 0.9903     \n",
      "Epoch 48/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0294 - acc: 0.9917     \n",
      "Epoch 49/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0291 - acc: 0.9917     \n",
      "Epoch 50/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0307 - acc: 0.9893     \n",
      "Epoch 51/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0285 - acc: 0.9912      \n",
      "Epoch 52/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0289 - acc: 0.9903     \n",
      "Epoch 53/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0283 - acc: 0.9903     \n",
      "Epoch 54/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0280 - acc: 0.9903     \n",
      "Epoch 55/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0281 - acc: 0.9912     \n",
      "Epoch 56/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0284 - acc: 0.9912     \n",
      "Epoch 57/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0287 - acc: 0.9893     \n",
      "Epoch 58/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0295 - acc: 0.9893     \n",
      "Epoch 59/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0284 - acc: 0.9903     \n",
      "Epoch 60/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0279 - acc: 0.9903     \n",
      "Epoch 61/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0276 - acc: 0.9908     \n",
      "Epoch 62/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0280 - acc: 0.9898     \n",
      "Epoch 63/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0285 - acc: 0.9912     \n",
      "Epoch 64/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0282 - acc: 0.9903     \n",
      "Epoch 65/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0284 - acc: 0.9903     \n",
      "Epoch 66/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0271 - acc: 0.9903     \n",
      "Epoch 67/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0279 - acc: 0.9908     \n",
      "Epoch 68/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0280 - acc: 0.9898     \n",
      "Epoch 69/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0276 - acc: 0.9888     \n",
      "Epoch 70/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0282 - acc: 0.9917     \n",
      "Epoch 71/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0272 - acc: 0.9898     \n",
      "Epoch 72/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0274 - acc: 0.9912     \n",
      "Epoch 73/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0278 - acc: 0.9908     \n",
      "Epoch 74/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0272 - acc: 0.9903     \n",
      "Epoch 75/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0272 - acc: 0.9898     \n",
      "Epoch 76/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0269 - acc: 0.9908     \n",
      "Epoch 77/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0278 - acc: 0.9908     \n",
      "Epoch 78/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0277 - acc: 0.9903     \n",
      "Epoch 79/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0269 - acc: 0.9903     \n",
      "Epoch 80/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0271 - acc: 0.9908     \n",
      "Epoch 81/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0275 - acc: 0.9903     \n",
      "Epoch 82/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0270 - acc: 0.9893     \n",
      "Epoch 83/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0269 - acc: 0.9908     \n",
      "Epoch 84/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0268 - acc: 0.9893     \n",
      "Epoch 85/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0268 - acc: 0.9912     \n",
      "Epoch 86/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0290 - acc: 0.9908     \n",
      "Epoch 87/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0284 - acc: 0.9893     \n",
      "Epoch 88/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0277 - acc: 0.9898     \n",
      "Epoch 89/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0268 - acc: 0.9908     \n",
      "Epoch 90/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0273 - acc: 0.9903     \n",
      "Epoch 91/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0276 - acc: 0.9898     \n",
      "Epoch 92/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0275 - acc: 0.9908     \n",
      "Epoch 93/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0262 - acc: 0.9912     \n",
      "Epoch 94/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0274 - acc: 0.9898     \n",
      "Epoch 95/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0269 - acc: 0.9898     \n",
      "Epoch 96/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0274 - acc: 0.9898     \n",
      "Epoch 97/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0271 - acc: 0.9912     \n",
      "Epoch 98/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0262 - acc: 0.9908     \n",
      "Epoch 99/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0275 - acc: 0.9898     \n",
      "Epoch 100/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0269 - acc: 0.9903     \n",
      " 32/229 [===>..........................] - ETA: 0sEpoch 1/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.6775 - acc: 0.8462     \n",
      "Epoch 2/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.5202 - acc: 0.8715     \n",
      "Epoch 3/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.2376 - acc: 0.9484     \n",
      "Epoch 4/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.1426 - acc: 0.9640     \n",
      "Epoch 5/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.1094 - acc: 0.9708     \n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 [==============================] - 0s - loss: 0.0934 - acc: 0.9762     \n",
      "Epoch 7/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0830 - acc: 0.9776     \n",
      "Epoch 8/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0758 - acc: 0.9796     \n",
      "Epoch 9/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0696 - acc: 0.9805     \n",
      "Epoch 10/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0645 - acc: 0.9820     \n",
      "Epoch 11/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0616 - acc: 0.9835     \n",
      "Epoch 12/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0578 - acc: 0.9844     \n",
      "Epoch 13/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0561 - acc: 0.9844     \n",
      "Epoch 14/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0515 - acc: 0.9854     \n",
      "Epoch 15/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0490 - acc: 0.9844     \n",
      "Epoch 16/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0471 - acc: 0.9869     \n",
      "Epoch 17/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0452 - acc: 0.9873     \n",
      "Epoch 18/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0440 - acc: 0.9883     \n",
      "Epoch 19/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0421 - acc: 0.9873     \n",
      "Epoch 20/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0406 - acc: 0.9888     \n",
      "Epoch 21/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0385 - acc: 0.9898     \n",
      "Epoch 22/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0380 - acc: 0.9898     \n",
      "Epoch 23/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0364 - acc: 0.9888     \n",
      "Epoch 24/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0351 - acc: 0.9903     \n",
      "Epoch 25/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0340 - acc: 0.9898     \n",
      "Epoch 26/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0334 - acc: 0.9898     \n",
      "Epoch 27/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0319 - acc: 0.9908     \n",
      "Epoch 28/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0318 - acc: 0.9898     \n",
      "Epoch 29/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0310 - acc: 0.9903     \n",
      "Epoch 30/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0305 - acc: 0.9908     \n",
      "Epoch 31/100\n",
      "  32/2055 [..............................] - ETA: 0s - loss: 0.0058 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.192423). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 [==============================] - 0s - loss: 0.0320 - acc: 0.9903     \n",
      "Epoch 32/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0309 - acc: 0.9912     \n",
      "Epoch 33/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0293 - acc: 0.9912     \n",
      "Epoch 34/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0290 - acc: 0.9912     \n",
      "Epoch 35/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0288 - acc: 0.9922     \n",
      "Epoch 36/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0277 - acc: 0.9912     \n",
      "Epoch 37/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0280 - acc: 0.9922     \n",
      "Epoch 38/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0275 - acc: 0.9922     \n",
      "Epoch 39/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0277 - acc: 0.9922     \n",
      "Epoch 40/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0265 - acc: 0.9917     \n",
      "Epoch 41/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0275 - acc: 0.9908     \n",
      "Epoch 42/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0267 - acc: 0.9912     \n",
      "Epoch 43/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0265 - acc: 0.9922     \n",
      "Epoch 44/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0263 - acc: 0.9927     \n",
      "Epoch 45/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0257 - acc: 0.9932     \n",
      "Epoch 46/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0260 - acc: 0.9922     \n",
      "Epoch 47/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0242 - acc: 0.9932     \n",
      "Epoch 48/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0261 - acc: 0.9922     \n",
      "Epoch 49/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0251 - acc: 0.9922     \n",
      "Epoch 50/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0256 - acc: 0.9917     \n",
      "Epoch 51/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0257 - acc: 0.9927     \n",
      "Epoch 52/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0252 - acc: 0.9922     \n",
      "Epoch 53/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0249 - acc: 0.9922     \n",
      "Epoch 54/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0248 - acc: 0.9932     \n",
      "Epoch 55/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0260 - acc: 0.9922     \n",
      "Epoch 56/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0240 - acc: 0.9932     \n",
      "Epoch 57/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0247 - acc: 0.9912     \n",
      "Epoch 58/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0237 - acc: 0.9937     \n",
      "Epoch 59/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0240 - acc: 0.9927     \n",
      "Epoch 60/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0236 - acc: 0.9932     \n",
      "Epoch 61/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0235 - acc: 0.9932     \n",
      "Epoch 62/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0243 - acc: 0.9932     \n",
      "Epoch 63/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0232 - acc: 0.9932     \n",
      "Epoch 64/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0244 - acc: 0.9927     \n",
      "Epoch 65/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0238 - acc: 0.9937     \n",
      "Epoch 66/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0234 - acc: 0.9937     \n",
      "Epoch 67/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0246 - acc: 0.9932     \n",
      "Epoch 68/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0239 - acc: 0.9922     \n",
      "Epoch 69/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0235 - acc: 0.9927     \n",
      "Epoch 70/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0231 - acc: 0.9927     \n",
      "Epoch 71/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0235 - acc: 0.9922     \n",
      "Epoch 72/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0232 - acc: 0.9932      \n",
      "Epoch 73/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0234 - acc: 0.9927     \n",
      "Epoch 74/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0231 - acc: 0.9927      \n",
      "Epoch 75/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0239 - acc: 0.9927     \n",
      "Epoch 76/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0244 - acc: 0.9922     \n",
      "Epoch 77/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0239 - acc: 0.9922     \n",
      "Epoch 78/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0234 - acc: 0.9932     \n",
      "Epoch 79/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0225 - acc: 0.9927     \n",
      "Epoch 80/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0230 - acc: 0.9927     \n",
      "Epoch 81/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0228 - acc: 0.9937     \n",
      "Epoch 82/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0223 - acc: 0.9932     \n",
      "Epoch 83/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0224 - acc: 0.9932     \n",
      "Epoch 84/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0227 - acc: 0.9932     \n",
      "Epoch 85/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0230 - acc: 0.9932     \n",
      "Epoch 86/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0230 - acc: 0.9927     \n",
      "Epoch 87/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0228 - acc: 0.9922      \n",
      "Epoch 88/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0233 - acc: 0.9927     \n",
      "Epoch 89/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0229 - acc: 0.9927     \n",
      "Epoch 90/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0224 - acc: 0.9927     \n",
      "Epoch 91/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0226 - acc: 0.9912     \n",
      "Epoch 92/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0224 - acc: 0.9932     \n",
      "Epoch 93/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0225 - acc: 0.9922     \n",
      "Epoch 94/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0222 - acc: 0.9932     \n",
      "Epoch 95/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0235 - acc: 0.9922     \n",
      "Epoch 96/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0214 - acc: 0.9932     \n",
      "Epoch 97/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0229 - acc: 0.9922     \n",
      "Epoch 98/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0221 - acc: 0.9932     \n",
      "Epoch 99/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0222 - acc: 0.9927     \n",
      "Epoch 100/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0225 - acc: 0.9937     \n",
      " 32/229 [===>..........................] - ETA: 0sEpoch 1/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.6793 - acc: 0.8433     \n",
      "Epoch 2/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.5481 - acc: 0.8540     \n",
      "Epoch 3/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.2663 - acc: 0.9367     \n",
      "Epoch 4/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.1573 - acc: 0.9611     \n",
      "Epoch 5/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.1139 - acc: 0.9698     \n",
      "Epoch 6/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0926 - acc: 0.9742     \n",
      "Epoch 7/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0815 - acc: 0.9781     \n",
      "Epoch 8/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0741 - acc: 0.9791     \n",
      "Epoch 9/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0676 - acc: 0.9815     \n",
      "Epoch 10/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0639 - acc: 0.9820     \n",
      "Epoch 11/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0608 - acc: 0.9825     \n",
      "Epoch 12/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0572 - acc: 0.9839     \n",
      "Epoch 13/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0555 - acc: 0.9839     \n",
      "Epoch 14/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0524 - acc: 0.9844     \n",
      "Epoch 15/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0510 - acc: 0.9844     \n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 [==============================] - 0s - loss: 0.0492 - acc: 0.9844     \n",
      "Epoch 17/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0466 - acc: 0.9869     \n",
      "Epoch 18/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0464 - acc: 0.9849     \n",
      "Epoch 19/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0446 - acc: 0.9873     \n",
      "Epoch 20/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0427 - acc: 0.9878     \n",
      "Epoch 21/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0410 - acc: 0.9864     \n",
      "Epoch 22/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0392 - acc: 0.9878     \n",
      "Epoch 23/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0383 - acc: 0.9873     \n",
      "Epoch 24/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0369 - acc: 0.9878     \n",
      "Epoch 25/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0363 - acc: 0.9893     \n",
      "Epoch 26/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0353 - acc: 0.9888     \n",
      "Epoch 27/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0340 - acc: 0.9903     \n",
      "Epoch 28/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0331 - acc: 0.9898     \n",
      "Epoch 29/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0332 - acc: 0.9903      \n",
      "Epoch 30/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0313 - acc: 0.9903     \n",
      "Epoch 31/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0303 - acc: 0.9912     \n",
      "Epoch 32/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0297 - acc: 0.9908     \n",
      "Epoch 33/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0289 - acc: 0.9917     \n",
      "Epoch 34/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0285 - acc: 0.9917     \n",
      "Epoch 35/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0276 - acc: 0.9927     \n",
      "Epoch 36/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0276 - acc: 0.9903     \n",
      "Epoch 37/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0266 - acc: 0.9932     \n",
      "Epoch 38/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0273 - acc: 0.9922     \n",
      "Epoch 39/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0272 - acc: 0.9922     \n",
      "Epoch 40/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0262 - acc: 0.9937     \n",
      "Epoch 41/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0263 - acc: 0.9927     \n",
      "Epoch 42/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0265 - acc: 0.9922     \n",
      "Epoch 43/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0281 - acc: 0.9917     \n",
      "Epoch 44/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0272 - acc: 0.9932     \n",
      "Epoch 45/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0255 - acc: 0.9942     \n",
      "Epoch 46/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0260 - acc: 0.9927     \n",
      "Epoch 47/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0250 - acc: 0.9942     \n",
      "Epoch 48/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0264 - acc: 0.9912     \n",
      "Epoch 49/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0254 - acc: 0.9932     \n",
      "Epoch 50/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0254 - acc: 0.9932     \n",
      "Epoch 51/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0251 - acc: 0.9937     \n",
      "Epoch 52/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0249 - acc: 0.9932     \n",
      "Epoch 53/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0245 - acc: 0.9937     \n",
      "Epoch 54/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0248 - acc: 0.9937     \n",
      "Epoch 55/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0249 - acc: 0.9942     \n",
      "Epoch 56/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0252 - acc: 0.9942     \n",
      "Epoch 57/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0249 - acc: 0.9932      \n",
      "Epoch 58/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0256 - acc: 0.9927     \n",
      "Epoch 59/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0250 - acc: 0.9932     \n",
      "Epoch 60/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0252 - acc: 0.9937     \n",
      "Epoch 61/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0244 - acc: 0.9932     \n",
      "Epoch 62/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0251 - acc: 0.9927     \n",
      "Epoch 63/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0239 - acc: 0.9942     \n",
      "Epoch 64/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0247 - acc: 0.9927     \n",
      "Epoch 65/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0244 - acc: 0.9937     \n",
      "Epoch 66/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0241 - acc: 0.9946     \n",
      "Epoch 67/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0244 - acc: 0.9942      \n",
      "Epoch 68/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0237 - acc: 0.9937     \n",
      "Epoch 69/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0239 - acc: 0.9942     \n",
      "Epoch 70/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0235 - acc: 0.9946     \n",
      "Epoch 71/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0238 - acc: 0.9932     \n",
      "Epoch 72/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0240 - acc: 0.9937     \n",
      "Epoch 73/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0245 - acc: 0.9932     \n",
      "Epoch 74/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0239 - acc: 0.9942     \n",
      "Epoch 75/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0246 - acc: 0.9942     \n",
      "Epoch 76/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0236 - acc: 0.9951     \n",
      "Epoch 77/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0244 - acc: 0.9937     \n",
      "Epoch 78/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0238 - acc: 0.9942     \n",
      "Epoch 79/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0235 - acc: 0.9946     \n",
      "Epoch 80/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0233 - acc: 0.9946     \n",
      "Epoch 81/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0236 - acc: 0.9942     \n",
      "Epoch 82/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0240 - acc: 0.9937     \n",
      "Epoch 83/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0232 - acc: 0.9946     \n",
      "Epoch 84/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0231 - acc: 0.9937     \n",
      "Epoch 85/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0241 - acc: 0.9927     \n",
      "Epoch 86/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0238 - acc: 0.9946     \n",
      "Epoch 87/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0234 - acc: 0.9942     \n",
      "Epoch 88/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0237 - acc: 0.9927     \n",
      "Epoch 89/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0234 - acc: 0.9937     \n",
      "Epoch 90/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0239 - acc: 0.9937     \n",
      "Epoch 91/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0230 - acc: 0.9937     \n",
      "Epoch 92/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0233 - acc: 0.9946     \n",
      "Epoch 93/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0243 - acc: 0.9932      \n",
      "Epoch 94/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0239 - acc: 0.9932     \n",
      "Epoch 95/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0230 - acc: 0.9942     \n",
      "Epoch 96/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0228 - acc: 0.9942     \n",
      "Epoch 97/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0242 - acc: 0.9942     \n",
      "Epoch 98/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0234 - acc: 0.9932     \n",
      "Epoch 99/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0234 - acc: 0.9942     \n",
      "Epoch 100/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0232 - acc: 0.9942     \n",
      " 32/229 [===>..........................] - ETA: 0sEpoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 [==============================] - 0s - loss: 0.6762 - acc: 0.8501     \n",
      "Epoch 2/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.4629 - acc: 0.8599     \n",
      "Epoch 3/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.2234 - acc: 0.9324     \n",
      "Epoch 4/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.1510 - acc: 0.9659     \n",
      "Epoch 5/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.1094 - acc: 0.9732     \n",
      "Epoch 6/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0892 - acc: 0.9781     \n",
      "Epoch 7/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0772 - acc: 0.9805     \n",
      "Epoch 8/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0686 - acc: 0.9815     \n",
      "Epoch 9/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0619 - acc: 0.9835     \n",
      "Epoch 10/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0582 - acc: 0.9830     \n",
      "Epoch 11/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0541 - acc: 0.9835     \n",
      "Epoch 12/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0520 - acc: 0.9849     \n",
      "Epoch 13/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0497 - acc: 0.9835     \n",
      "Epoch 14/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0479 - acc: 0.9844     \n",
      "Epoch 15/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0461 - acc: 0.9859     \n",
      "Epoch 16/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0446 - acc: 0.9854     \n",
      "Epoch 17/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0426 - acc: 0.9869     \n",
      "Epoch 18/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0411 - acc: 0.9883     \n",
      "Epoch 19/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0400 - acc: 0.9878     \n",
      "Epoch 20/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0395 - acc: 0.9878     \n",
      "Epoch 21/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0380 - acc: 0.9883     \n",
      "Epoch 22/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0370 - acc: 0.9888     \n",
      "Epoch 23/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0355 - acc: 0.9873     \n",
      "Epoch 24/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0345 - acc: 0.9898     \n",
      "Epoch 25/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0335 - acc: 0.9883     \n",
      "Epoch 26/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0331 - acc: 0.9903     \n",
      "Epoch 27/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0322 - acc: 0.9888     \n",
      "Epoch 28/100\n",
      "2055/2055 [==============================] - ETA: 0s - loss: 0.0342 - acc: 0.989 - 0s - loss: 0.0310 - acc: 0.9903     \n",
      "Epoch 29/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0308 - acc: 0.9903     \n",
      "Epoch 30/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0303 - acc: 0.9908     \n",
      "Epoch 31/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0292 - acc: 0.9917     \n",
      "Epoch 32/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0289 - acc: 0.9917     \n",
      "Epoch 33/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0284 - acc: 0.9917     \n",
      "Epoch 34/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0273 - acc: 0.9917     \n",
      "Epoch 35/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0276 - acc: 0.9912     \n",
      "Epoch 36/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0266 - acc: 0.9927     \n",
      "Epoch 37/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0267 - acc: 0.9922     \n",
      "Epoch 38/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0267 - acc: 0.9927     \n",
      "Epoch 39/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0261 - acc: 0.9917     \n",
      "Epoch 40/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0257 - acc: 0.9937     \n",
      "Epoch 41/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0257 - acc: 0.9927     \n",
      "Epoch 42/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0254 - acc: 0.9937     \n",
      "Epoch 43/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0248 - acc: 0.9942     \n",
      "Epoch 44/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0247 - acc: 0.9937     \n",
      "Epoch 45/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0249 - acc: 0.9917     \n",
      "Epoch 46/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0244 - acc: 0.9932     \n",
      "Epoch 47/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0248 - acc: 0.9927     \n",
      "Epoch 48/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0247 - acc: 0.9932     \n",
      "Epoch 49/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0252 - acc: 0.9922     \n",
      "Epoch 50/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0253 - acc: 0.9932     \n",
      "Epoch 51/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0241 - acc: 0.9922     \n",
      "Epoch 52/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0239 - acc: 0.9946     \n",
      "Epoch 53/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0237 - acc: 0.9932     \n",
      "Epoch 54/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0237 - acc: 0.9942     \n",
      "Epoch 55/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0234 - acc: 0.9942     \n",
      "Epoch 56/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0245 - acc: 0.9927     \n",
      "Epoch 57/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0229 - acc: 0.9946     \n",
      "Epoch 58/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0235 - acc: 0.9942     \n",
      "Epoch 59/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0228 - acc: 0.9932     \n",
      "Epoch 60/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0245 - acc: 0.9932     \n",
      "Epoch 61/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0225 - acc: 0.9946     \n",
      "Epoch 62/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0230 - acc: 0.9937     \n",
      "Epoch 63/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0231 - acc: 0.9927     \n",
      "Epoch 64/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0235 - acc: 0.9937     \n",
      "Epoch 65/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0222 - acc: 0.9946     \n",
      "Epoch 66/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0232 - acc: 0.9942      \n",
      "Epoch 67/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0231 - acc: 0.9942     \n",
      "Epoch 68/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0229 - acc: 0.9937     \n",
      "Epoch 69/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0229 - acc: 0.9942     \n",
      "Epoch 70/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0225 - acc: 0.9927     \n",
      "Epoch 71/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0229 - acc: 0.9942     \n",
      "Epoch 72/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0220 - acc: 0.9946     \n",
      "Epoch 73/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0230 - acc: 0.9937     \n",
      "Epoch 74/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0217 - acc: 0.9946     \n",
      "Epoch 75/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0218 - acc: 0.9927     \n",
      "Epoch 76/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0229 - acc: 0.9932     \n",
      "Epoch 77/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0220 - acc: 0.9932     \n",
      "Epoch 78/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0220 - acc: 0.9937     \n",
      "Epoch 79/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0218 - acc: 0.9937     \n",
      "Epoch 80/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0213 - acc: 0.9937     \n",
      "Epoch 81/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0213 - acc: 0.9942     \n",
      "Epoch 82/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0225 - acc: 0.9942     \n",
      "Epoch 83/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0223 - acc: 0.9932     \n",
      "Epoch 84/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0215 - acc: 0.9937     \n",
      "Epoch 85/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0213 - acc: 0.9946     \n",
      "Epoch 86/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0215 - acc: 0.9937     \n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 [==============================] - 0s - loss: 0.0221 - acc: 0.9942     \n",
      "Epoch 88/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0217 - acc: 0.9942     \n",
      "Epoch 89/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0206 - acc: 0.9946     \n",
      "Epoch 90/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0217 - acc: 0.9937      \n",
      "Epoch 91/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0211 - acc: 0.9942     \n",
      "Epoch 92/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0221 - acc: 0.9937     \n",
      "Epoch 93/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0207 - acc: 0.9951     \n",
      "Epoch 94/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0212 - acc: 0.9946     \n",
      "Epoch 95/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0216 - acc: 0.9942     \n",
      "Epoch 96/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0209 - acc: 0.9951      \n",
      "Epoch 97/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0211 - acc: 0.9937      \n",
      "Epoch 98/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0206 - acc: 0.9942      \n",
      "Epoch 99/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0221 - acc: 0.9942     \n",
      "Epoch 100/100\n",
      "2055/2055 [==============================] - 0s - loss: 0.0212 - acc: 0.9942     \n",
      " 32/229 [===>..........................] - ETA: 0sEpoch 1/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.6749 - acc: 0.8551     \n",
      "Epoch 2/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.4552 - acc: 0.8555     \n",
      "Epoch 3/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.2316 - acc: 0.8555     \n",
      "Epoch 4/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1943 - acc: 0.8555     \n",
      "Epoch 5/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1741 - acc: 0.8555     \n",
      "Epoch 6/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1595 - acc: 0.8555     \n",
      "Epoch 7/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1502 - acc: 0.8555     \n",
      "Epoch 8/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1431 - acc: 0.8653     \n",
      "Epoch 9/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1377 - acc: 0.9796     \n",
      "Epoch 10/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1325 - acc: 0.9796     \n",
      "Epoch 11/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1284 - acc: 0.9805     \n",
      "Epoch 12/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1246 - acc: 0.9854     \n",
      "Epoch 13/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1217 - acc: 0.9820     \n",
      "Epoch 14/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1183 - acc: 0.9844     \n",
      "Epoch 15/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1145 - acc: 0.9854     \n",
      "Epoch 16/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1119 - acc: 0.9835     \n",
      "Epoch 17/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1085 - acc: 0.9874     \n",
      "Epoch 18/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1059 - acc: 0.9864     - ETA: 0s - loss: 0.1185 - acc: 0.9\n",
      "Epoch 19/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1033 - acc: 0.9869     \n",
      "Epoch 20/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1004 - acc: 0.9869     \n",
      "Epoch 21/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0978 - acc: 0.9878     \n",
      "Epoch 22/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0952 - acc: 0.9869     \n",
      "Epoch 23/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0931 - acc: 0.9893     \n",
      "Epoch 24/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0908 - acc: 0.9874     \n",
      "Epoch 25/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0884 - acc: 0.9903     \n",
      "Epoch 26/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0868 - acc: 0.9893     \n",
      "Epoch 27/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0856 - acc: 0.9883     \n",
      "Epoch 28/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0821 - acc: 0.9908     \n",
      "Epoch 29/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0806 - acc: 0.9893     \n",
      "Epoch 30/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0788 - acc: 0.9908     \n",
      "Epoch 31/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0766 - acc: 0.9903     \n",
      "Epoch 32/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0750 - acc: 0.9908     \n",
      "Epoch 33/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0735 - acc: 0.9903     \n",
      "Epoch 34/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0730 - acc: 0.9908     \n",
      "Epoch 35/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0709 - acc: 0.9912     \n",
      "Epoch 36/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0694 - acc: 0.9912     \n",
      "Epoch 37/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0678 - acc: 0.9922     \n",
      "Epoch 38/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0670 - acc: 0.9922     \n",
      "Epoch 39/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0651 - acc: 0.9922     - ETA: 0s - loss: 0.0731 - acc: 0.9\n",
      "Epoch 40/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0649 - acc: 0.9912     \n",
      "Epoch 41/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0626 - acc: 0.9922     \n",
      "Epoch 42/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0611 - acc: 0.9917     \n",
      "Epoch 43/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0607 - acc: 0.9922     \n",
      "Epoch 44/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0596 - acc: 0.9917     \n",
      "Epoch 45/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0578 - acc: 0.9922     \n",
      "Epoch 46/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0573 - acc: 0.9922     \n",
      "Epoch 47/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0563 - acc: 0.9917     \n",
      "Epoch 48/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0553 - acc: 0.9922     \n",
      "Epoch 49/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0543 - acc: 0.9922     \n",
      "Epoch 50/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0534 - acc: 0.9917     \n",
      "Epoch 51/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0536 - acc: 0.9917     \n",
      "Epoch 52/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0534 - acc: 0.9908     \n",
      "Epoch 53/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0514 - acc: 0.9922     \n",
      "Epoch 54/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0514 - acc: 0.9917     \n",
      "Epoch 55/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0497 - acc: 0.9922     \n",
      "Epoch 56/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0497 - acc: 0.9917     \n",
      "Epoch 57/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0485 - acc: 0.9912     \n",
      "Epoch 58/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0479 - acc: 0.9917     \n",
      "Epoch 59/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0471 - acc: 0.9922     \n",
      "Epoch 60/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0466 - acc: 0.9917     \n",
      "Epoch 61/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0470 - acc: 0.9922     \n",
      "Epoch 62/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0453 - acc: 0.9917     \n",
      "Epoch 63/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0452 - acc: 0.9917     \n",
      "Epoch 64/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0450 - acc: 0.9922     \n",
      "Epoch 65/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0439 - acc: 0.9922     - ETA: 0s - loss: 0.0439 - acc: 0.992 - ETA: 0s - loss: 0.0439 - acc: 0.991\n",
      "Epoch 66/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0436 - acc: 0.9917     \n",
      "Epoch 67/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0434 - acc: 0.9917     \n",
      "Epoch 68/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0432 - acc: 0.9912     \n",
      "Epoch 69/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0423 - acc: 0.9912     \n",
      "Epoch 70/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0418 - acc: 0.9917     \n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 0s - loss: 0.0417 - acc: 0.9922     \n",
      "Epoch 72/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0408 - acc: 0.9912     \n",
      "Epoch 73/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0404 - acc: 0.9917     \n",
      "Epoch 74/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0404 - acc: 0.9917     \n",
      "Epoch 75/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0399 - acc: 0.9917     \n",
      "Epoch 76/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0403 - acc: 0.9912     \n",
      "Epoch 77/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0393 - acc: 0.9917     \n",
      "Epoch 78/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0390 - acc: 0.9912     \n",
      "Epoch 79/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0387 - acc: 0.9922     \n",
      "Epoch 80/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0384 - acc: 0.9917     \n",
      "Epoch 81/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0394 - acc: 0.9903     \n",
      "Epoch 82/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0382 - acc: 0.9917     \n",
      "Epoch 83/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0379 - acc: 0.9917     \n",
      "Epoch 84/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0372 - acc: 0.9917     \n",
      "Epoch 85/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0373 - acc: 0.9912     \n",
      "Epoch 86/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0369 - acc: 0.9922     \n",
      "Epoch 87/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0365 - acc: 0.9922     \n",
      "Epoch 88/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0373 - acc: 0.9903     \n",
      "Epoch 89/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0361 - acc: 0.9922     \n",
      "Epoch 90/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0359 - acc: 0.9922     \n",
      "Epoch 91/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0362 - acc: 0.9912     \n",
      "Epoch 92/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0358 - acc: 0.9927     \n",
      "Epoch 93/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0353 - acc: 0.9917     \n",
      "Epoch 94/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0359 - acc: 0.9917     - ETA: 0s - loss: 0.0273 - acc: 0.99\n",
      "Epoch 95/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0351 - acc: 0.9917     \n",
      "Epoch 96/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0347 - acc: 0.9917     \n",
      "Epoch 97/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0348 - acc: 0.9917     \n",
      "Epoch 98/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0347 - acc: 0.9917     \n",
      "Epoch 99/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0347 - acc: 0.9927     \n",
      "Epoch 100/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0347 - acc: 0.9922     \n",
      " 32/228 [===>..........................] - ETA: 0sEpoch 1/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.6719 - acc: 0.8536     \n",
      "Epoch 2/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.4239 - acc: 0.8541     \n",
      "Epoch 3/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.2466 - acc: 0.8541     \n",
      "Epoch 4/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.2097 - acc: 0.8541     \n",
      "Epoch 5/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1841 - acc: 0.8541     \n",
      "Epoch 6/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1696 - acc: 0.8541     \n",
      "Epoch 7/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1595 - acc: 0.8541     \n",
      "Epoch 8/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1514 - acc: 0.9222     \n",
      "Epoch 9/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1450 - acc: 0.9752     \n",
      "Epoch 10/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1391 - acc: 0.9805     \n",
      "Epoch 11/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1341 - acc: 0.9805     \n",
      "Epoch 12/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1295 - acc: 0.9820     - ETA: 0s - loss: 0.1276 - acc: 0.982\n",
      "Epoch 13/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1254 - acc: 0.9830     \n",
      "Epoch 14/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1217 - acc: 0.9839     \n",
      "Epoch 15/100\n",
      "2056/2056 [==============================] - ETA: 0s - loss: 0.1169 - acc: 0.9850- ETA: 0s - loss: 0.1200 - acc: 0.9 - 0s - loss: 0.1183 - acc: 0.9854     \n",
      "Epoch 16/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1150 - acc: 0.9859     \n",
      "Epoch 17/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1118 - acc: 0.9864     \n",
      "Epoch 18/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1087 - acc: 0.9864     \n",
      "Epoch 19/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1059 - acc: 0.9864     \n",
      "Epoch 20/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1034 - acc: 0.9874     \n",
      "Epoch 21/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1001 - acc: 0.9888     \n",
      "Epoch 22/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0976 - acc: 0.9878     \n",
      "Epoch 23/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0954 - acc: 0.9888     \n",
      "Epoch 24/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0926 - acc: 0.9888     \n",
      "Epoch 25/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0908 - acc: 0.9893     \n",
      "Epoch 26/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0879 - acc: 0.9898     \n",
      "Epoch 27/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0861 - acc: 0.9898     \n",
      "Epoch 28/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0839 - acc: 0.9903     \n",
      "Epoch 29/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0821 - acc: 0.9898     \n",
      "Epoch 30/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0803 - acc: 0.9912     \n",
      "Epoch 31/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0783 - acc: 0.9908     \n",
      "Epoch 32/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0764 - acc: 0.9912     \n",
      "Epoch 33/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0750 - acc: 0.9903     \n",
      "Epoch 34/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0733 - acc: 0.9908     \n",
      "Epoch 35/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0717 - acc: 0.9908     \n",
      "Epoch 36/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0702 - acc: 0.9903     \n",
      "Epoch 37/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0685 - acc: 0.9917     - ETA: 0s - loss: 0.0668 - acc: 0.99\n",
      "Epoch 38/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0674 - acc: 0.9912     \n",
      "Epoch 39/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0659 - acc: 0.9917     \n",
      "Epoch 40/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0647 - acc: 0.9912     \n",
      "Epoch 41/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0635 - acc: 0.9912     \n",
      "Epoch 42/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0622 - acc: 0.9917     \n",
      "Epoch 43/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0612 - acc: 0.9912     \n",
      "Epoch 44/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0599 - acc: 0.9912     \n",
      "Epoch 45/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0590 - acc: 0.9912     \n",
      "Epoch 46/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0583 - acc: 0.9908     \n",
      "Epoch 47/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0566 - acc: 0.9917     \n",
      "Epoch 48/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0560 - acc: 0.9917     \n",
      "Epoch 49/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0549 - acc: 0.9917     \n",
      "Epoch 50/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0545 - acc: 0.9922     \n",
      "Epoch 51/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0536 - acc: 0.9903     \n",
      "Epoch 52/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0532 - acc: 0.9917     \n",
      "Epoch 53/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0521 - acc: 0.9908     \n",
      "Epoch 54/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0516 - acc: 0.9903     \n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 0s - loss: 0.0500 - acc: 0.9908     \n",
      "Epoch 56/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0502 - acc: 0.9922     \n",
      "Epoch 57/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0493 - acc: 0.9912     \n",
      "Epoch 58/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0480 - acc: 0.9917     \n",
      "Epoch 59/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0476 - acc: 0.9908     \n",
      "Epoch 60/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0476 - acc: 0.9917     \n",
      "Epoch 61/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0464 - acc: 0.9912     \n",
      "Epoch 62/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0459 - acc: 0.9908     \n",
      "Epoch 63/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0454 - acc: 0.9922     \n",
      "Epoch 64/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0448 - acc: 0.9917     \n",
      "Epoch 65/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0443 - acc: 0.9908     \n",
      "Epoch 66/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0443 - acc: 0.9908     \n",
      "Epoch 67/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0436 - acc: 0.9912     \n",
      "Epoch 68/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0435 - acc: 0.9912     \n",
      "Epoch 69/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0427 - acc: 0.9912     \n",
      "Epoch 70/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0422 - acc: 0.9912     \n",
      "Epoch 71/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0419 - acc: 0.9898     \n",
      "Epoch 72/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0413 - acc: 0.9912     \n",
      "Epoch 73/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0411 - acc: 0.9912     \n",
      "Epoch 74/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0408 - acc: 0.9917     \n",
      "Epoch 75/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0405 - acc: 0.9917     \n",
      "Epoch 76/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0398 - acc: 0.9922     \n",
      "Epoch 77/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0394 - acc: 0.9908     \n",
      "Epoch 78/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0391 - acc: 0.9917     \n",
      "Epoch 79/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0386 - acc: 0.9917     \n",
      "Epoch 80/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0386 - acc: 0.9912     \n",
      "Epoch 81/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0381 - acc: 0.9908     \n",
      "Epoch 82/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0381 - acc: 0.9922     \n",
      "Epoch 83/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0381 - acc: 0.9917     \n",
      "Epoch 84/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0379 - acc: 0.9917     \n",
      "Epoch 85/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0372 - acc: 0.9917     \n",
      "Epoch 86/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0371 - acc: 0.9927     \n",
      "Epoch 87/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0369 - acc: 0.9917     \n",
      "Epoch 88/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0368 - acc: 0.9912     \n",
      "Epoch 89/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0362 - acc: 0.9917     \n",
      "Epoch 90/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0361 - acc: 0.9917     - ETA: 0s - loss: 0.0367 - acc: 0.991\n",
      "Epoch 91/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0359 - acc: 0.9908     \n",
      "Epoch 92/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0365 - acc: 0.9903     \n",
      "Epoch 93/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0353 - acc: 0.9922     \n",
      "Epoch 94/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0361 - acc: 0.9912     \n",
      "Epoch 95/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0348 - acc: 0.9917     \n",
      "Epoch 96/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0348 - acc: 0.9917     \n",
      "Epoch 97/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0349 - acc: 0.9908     \n",
      "Epoch 98/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0345 - acc: 0.9903     \n",
      "Epoch 99/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0347 - acc: 0.9922     \n",
      "Epoch 100/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0344 - acc: 0.9917     \n",
      " 32/228 [===>..........................] - ETA: 0sEpoch 1/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.6701 - acc: 0.8521     \n",
      "Epoch 2/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.4266 - acc: 0.8521     \n",
      "Epoch 3/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.2430 - acc: 0.8521     \n",
      "Epoch 4/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.2089 - acc: 0.8521     \n",
      "Epoch 5/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1858 - acc: 0.8521     \n",
      "Epoch 6/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1689 - acc: 0.8521     \n",
      "Epoch 7/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1582 - acc: 0.8521     \n",
      "Epoch 8/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1505 - acc: 0.9319     \n",
      "Epoch 9/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1435 - acc: 0.9776     \n",
      "Epoch 10/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1379 - acc: 0.9796     \n",
      "Epoch 11/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1327 - acc: 0.9820     \n",
      "Epoch 12/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1287 - acc: 0.9815     \n",
      "Epoch 13/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1248 - acc: 0.9839     \n",
      "Epoch 14/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1217 - acc: 0.9844     \n",
      "Epoch 15/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1180 - acc: 0.9830     \n",
      "Epoch 16/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1146 - acc: 0.9839     \n",
      "Epoch 17/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1113 - acc: 0.9849     \n",
      "Epoch 18/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1084 - acc: 0.9864     \n",
      "Epoch 19/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1053 - acc: 0.9864     \n",
      "Epoch 20/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1026 - acc: 0.9883     \n",
      "Epoch 21/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0998 - acc: 0.9878     \n",
      "Epoch 22/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0975 - acc: 0.9883     \n",
      "Epoch 23/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0949 - acc: 0.9893     \n",
      "Epoch 24/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0924 - acc: 0.9898     \n",
      "Epoch 25/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0902 - acc: 0.9898     \n",
      "Epoch 26/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0886 - acc: 0.9874     \n",
      "Epoch 27/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0859 - acc: 0.9893     \n",
      "Epoch 28/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0842 - acc: 0.9888     \n",
      "Epoch 29/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0821 - acc: 0.9903     \n",
      "Epoch 30/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0803 - acc: 0.9903     \n",
      "Epoch 31/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0784 - acc: 0.9908     \n",
      "Epoch 32/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0772 - acc: 0.9898     \n",
      "Epoch 33/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0753 - acc: 0.9912     \n",
      "Epoch 34/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0740 - acc: 0.9912     \n",
      "Epoch 35/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0725 - acc: 0.9898     \n",
      "Epoch 36/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0708 - acc: 0.9903     \n",
      "Epoch 37/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0694 - acc: 0.9912     \n",
      "Epoch 38/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0684 - acc: 0.9912     \n",
      "Epoch 39/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0671 - acc: 0.9912     \n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 0s - loss: 0.0658 - acc: 0.9912     \n",
      "Epoch 41/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0645 - acc: 0.9912     \n",
      "Epoch 42/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0637 - acc: 0.9908     \n",
      "Epoch 43/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0627 - acc: 0.9912     \n",
      "Epoch 44/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0616 - acc: 0.9912     \n",
      "Epoch 45/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0602 - acc: 0.9912     \n",
      "Epoch 46/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0594 - acc: 0.9917     \n",
      "Epoch 47/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0586 - acc: 0.9917     \n",
      "Epoch 48/100\n",
      "2056/2056 [==============================] - ETA: 0s - loss: 0.0472 - acc: 0.993 - 0s - loss: 0.0575 - acc: 0.9908     \n",
      "Epoch 49/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0573 - acc: 0.9912     \n",
      "Epoch 50/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0559 - acc: 0.9912     \n",
      "Epoch 51/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0554 - acc: 0.9908     \n",
      "Epoch 52/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0542 - acc: 0.9908     \n",
      "Epoch 53/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0535 - acc: 0.9912     \n",
      "Epoch 54/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0531 - acc: 0.9917     \n",
      "Epoch 55/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0530 - acc: 0.9908     \n",
      "Epoch 56/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0518 - acc: 0.9912     \n",
      "Epoch 57/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0509 - acc: 0.9912     \n",
      "Epoch 58/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0499 - acc: 0.9912     \n",
      "Epoch 59/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0502 - acc: 0.9908     \n",
      "Epoch 60/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0490 - acc: 0.9912     \n",
      "Epoch 61/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0485 - acc: 0.9903     \n",
      "Epoch 62/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0485 - acc: 0.9908     \n",
      "Epoch 63/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0478 - acc: 0.9912     \n",
      "Epoch 64/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0470 - acc: 0.9908     \n",
      "Epoch 65/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0465 - acc: 0.9903     \n",
      "Epoch 66/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0467 - acc: 0.9908     \n",
      "Epoch 67/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0453 - acc: 0.9898     \n",
      "Epoch 68/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0458 - acc: 0.9908     \n",
      "Epoch 69/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0454 - acc: 0.9903     \n",
      "Epoch 70/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0445 - acc: 0.9912     \n",
      "Epoch 71/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0439 - acc: 0.9912     \n",
      "Epoch 72/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0437 - acc: 0.9908     \n",
      "Epoch 73/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0433 - acc: 0.9903     \n",
      "Epoch 74/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0428 - acc: 0.9912     \n",
      "Epoch 75/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0425 - acc: 0.9912     \n",
      "Epoch 76/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0425 - acc: 0.9908     \n",
      "Epoch 77/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0419 - acc: 0.9908     \n",
      "Epoch 78/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0416 - acc: 0.9903     \n",
      "Epoch 79/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0414 - acc: 0.9908     \n",
      "Epoch 80/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0410 - acc: 0.9903     \n",
      "Epoch 81/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0408 - acc: 0.9908     \n",
      "Epoch 82/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0406 - acc: 0.9908     \n",
      "Epoch 83/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0404 - acc: 0.9898     \n",
      "Epoch 84/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0397 - acc: 0.9908     \n",
      "Epoch 85/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0401 - acc: 0.9903     \n",
      "Epoch 86/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0402 - acc: 0.9903     \n",
      "Epoch 87/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0391 - acc: 0.9908     \n",
      "Epoch 88/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0391 - acc: 0.9908     \n",
      "Epoch 89/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0388 - acc: 0.9908     \n",
      "Epoch 90/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0384 - acc: 0.9908     \n",
      "Epoch 91/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0385 - acc: 0.9912     \n",
      "Epoch 92/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0379 - acc: 0.9912     \n",
      "Epoch 93/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0380 - acc: 0.9908     \n",
      "Epoch 94/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0380 - acc: 0.9908     \n",
      "Epoch 95/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0376 - acc: 0.9903     \n",
      "Epoch 96/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0375 - acc: 0.9908     \n",
      "Epoch 97/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0376 - acc: 0.9903     \n",
      "Epoch 98/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0372 - acc: 0.9898     \n",
      "Epoch 99/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0367 - acc: 0.9917     \n",
      "Epoch 100/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0378 - acc: 0.9908     \n",
      " 32/228 [===>..........................] - ETA: 0sEpoch 1/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.6758 - acc: 0.8453     \n",
      "Epoch 2/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.4471 - acc: 0.8551     \n",
      "Epoch 3/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.2420 - acc: 0.8551     \n",
      "Epoch 4/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.2087 - acc: 0.8551     \n",
      "Epoch 5/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1878 - acc: 0.8551     \n",
      "Epoch 6/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1711 - acc: 0.8551     \n",
      "Epoch 7/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1593 - acc: 0.8551     \n",
      "Epoch 8/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1512 - acc: 0.8857     \n",
      "Epoch 9/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1436 - acc: 0.9757     \n",
      "Epoch 10/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1373 - acc: 0.9791     \n",
      "Epoch 11/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1323 - acc: 0.9796     \n",
      "Epoch 12/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1277 - acc: 0.9810     \n",
      "Epoch 13/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1235 - acc: 0.9844     \n",
      "Epoch 14/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1203 - acc: 0.9839     \n",
      "Epoch 15/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1165 - acc: 0.9839     \n",
      "Epoch 16/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1133 - acc: 0.9854     \n",
      "Epoch 17/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1106 - acc: 0.9854     \n",
      "Epoch 18/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1074 - acc: 0.9864     \n",
      "Epoch 19/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1047 - acc: 0.9878     \n",
      "Epoch 20/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1019 - acc: 0.9878     \n",
      "Epoch 21/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0985 - acc: 0.9888     \n",
      "Epoch 22/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0960 - acc: 0.9878     \n",
      "Epoch 23/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0938 - acc: 0.9878     \n",
      "Epoch 24/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0914 - acc: 0.9888     \n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 0s - loss: 0.0891 - acc: 0.9883     \n",
      "Epoch 26/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0869 - acc: 0.9878     \n",
      "Epoch 27/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0848 - acc: 0.9883     \n",
      "Epoch 28/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0827 - acc: 0.9874     \n",
      "Epoch 29/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0803 - acc: 0.9898     \n",
      "Epoch 30/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0793 - acc: 0.9898     \n",
      "Epoch 31/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0770 - acc: 0.9908     \n",
      "Epoch 32/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0751 - acc: 0.9917     \n",
      "Epoch 33/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0737 - acc: 0.9898     \n",
      "Epoch 34/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0723 - acc: 0.9922     \n",
      "Epoch 35/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0711 - acc: 0.9917     \n",
      "Epoch 36/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0695 - acc: 0.9922     \n",
      "Epoch 37/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0686 - acc: 0.9898     \n",
      "Epoch 38/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0667 - acc: 0.9912     \n",
      "Epoch 39/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0654 - acc: 0.9922     \n",
      "Epoch 40/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0642 - acc: 0.9927     \n",
      "Epoch 41/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0631 - acc: 0.9917     \n",
      "Epoch 42/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0620 - acc: 0.9922     \n",
      "Epoch 43/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0605 - acc: 0.9927     \n",
      "Epoch 44/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0601 - acc: 0.9922     \n",
      "Epoch 45/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0587 - acc: 0.9917     \n",
      "Epoch 46/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0579 - acc: 0.9922     \n",
      "Epoch 47/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0572 - acc: 0.9917     \n",
      "Epoch 48/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0556 - acc: 0.9927     \n",
      "Epoch 49/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0552 - acc: 0.9917     \n",
      "Epoch 50/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0544 - acc: 0.9917     \n",
      "Epoch 51/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0531 - acc: 0.9932     \n",
      "Epoch 52/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0531 - acc: 0.9908     \n",
      "Epoch 53/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0519 - acc: 0.9917     \n",
      "Epoch 54/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0512 - acc: 0.9917     \n",
      "Epoch 55/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0504 - acc: 0.9917     \n",
      "Epoch 56/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0500 - acc: 0.9912     \n",
      "Epoch 57/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0491 - acc: 0.9917     \n",
      "Epoch 58/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0486 - acc: 0.9922     \n",
      "Epoch 59/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0478 - acc: 0.9927     \n",
      "Epoch 60/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0472 - acc: 0.9912     \n",
      "Epoch 61/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0468 - acc: 0.9917     \n",
      "Epoch 62/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0460 - acc: 0.9927     \n",
      "Epoch 63/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0454 - acc: 0.9927     \n",
      "Epoch 64/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0450 - acc: 0.9917     \n",
      "Epoch 65/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0446 - acc: 0.9912     \n",
      "Epoch 66/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0442 - acc: 0.9927     \n",
      "Epoch 67/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0439 - acc: 0.9912     \n",
      "Epoch 68/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0430 - acc: 0.9927     \n",
      "Epoch 69/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0431 - acc: 0.9908     \n",
      "Epoch 70/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0422 - acc: 0.9932     \n",
      "Epoch 71/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0423 - acc: 0.9922     \n",
      "Epoch 72/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0419 - acc: 0.9927     \n",
      "Epoch 73/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0417 - acc: 0.9917     \n",
      "Epoch 74/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0411 - acc: 0.9917     \n",
      "Epoch 75/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0405 - acc: 0.9917     \n",
      "Epoch 76/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0402 - acc: 0.9927     \n",
      "Epoch 77/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0399 - acc: 0.9917     \n",
      "Epoch 78/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0394 - acc: 0.9932     \n",
      "Epoch 79/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0394 - acc: 0.9927     \n",
      "Epoch 80/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0391 - acc: 0.9932     \n",
      "Epoch 81/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0385 - acc: 0.9927     \n",
      "Epoch 82/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0384 - acc: 0.9922     \n",
      "Epoch 83/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0385 - acc: 0.9922     \n",
      "Epoch 84/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0379 - acc: 0.9927     \n",
      "Epoch 85/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0379 - acc: 0.9932     \n",
      "Epoch 86/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0374 - acc: 0.9917     \n",
      "Epoch 87/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0373 - acc: 0.9917     \n",
      "Epoch 88/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0369 - acc: 0.9927     \n",
      "Epoch 89/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0369 - acc: 0.9927     - ETA: 0s - loss: 0.0361 - acc: 0.992\n",
      "Epoch 90/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0368 - acc: 0.9932     \n",
      "Epoch 91/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0360 - acc: 0.9917     \n",
      "Epoch 92/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0364 - acc: 0.9922     \n",
      "Epoch 93/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0359 - acc: 0.9927     \n",
      "Epoch 94/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0358 - acc: 0.9927     \n",
      "Epoch 95/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0353 - acc: 0.9932     \n",
      "Epoch 96/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0351 - acc: 0.9927     \n",
      "Epoch 97/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0349 - acc: 0.9922     \n",
      "Epoch 98/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0347 - acc: 0.9917     \n",
      "Epoch 99/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0348 - acc: 0.9932     \n",
      "Epoch 100/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0349 - acc: 0.9927     \n",
      " 32/228 [===>..........................] - ETA: 0sEpoch 1/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.6757 - acc: 0.8492     \n",
      "Epoch 2/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.4802 - acc: 0.8507     \n",
      "Epoch 3/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.2704 - acc: 0.8507     \n",
      "Epoch 4/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.2320 - acc: 0.8507     \n",
      "Epoch 5/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.2102 - acc: 0.8507     \n",
      "Epoch 6/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1917 - acc: 0.8507     \n",
      "Epoch 7/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1770 - acc: 0.8507     \n",
      "Epoch 8/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1666 - acc: 0.8507     \n",
      "Epoch 9/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1585 - acc: 0.9475     \n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 0s - loss: 0.1520 - acc: 0.9723     \n",
      "Epoch 11/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1462 - acc: 0.9767     \n",
      "Epoch 12/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1410 - acc: 0.9786     \n",
      "Epoch 13/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1362 - acc: 0.9771     \n",
      "Epoch 14/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1319 - acc: 0.9796     \n",
      "Epoch 15/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1279 - acc: 0.9796     \n",
      "Epoch 16/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1242 - acc: 0.9815     \n",
      "Epoch 17/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1205 - acc: 0.9815     \n",
      "Epoch 18/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1174 - acc: 0.9825     \n",
      "Epoch 19/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1140 - acc: 0.9830     \n",
      "Epoch 20/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1111 - acc: 0.9844     \n",
      "Epoch 21/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1083 - acc: 0.9849     \n",
      "Epoch 22/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1053 - acc: 0.9854     \n",
      "Epoch 23/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1029 - acc: 0.9854     \n",
      "Epoch 24/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1000 - acc: 0.9874     \n",
      "Epoch 25/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0973 - acc: 0.9859     \n",
      "Epoch 26/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0949 - acc: 0.9878     \n",
      "Epoch 27/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0928 - acc: 0.9874     \n",
      "Epoch 28/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0905 - acc: 0.9878     \n",
      "Epoch 29/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0883 - acc: 0.9874     \n",
      "Epoch 30/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0864 - acc: 0.9878     \n",
      "Epoch 31/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0845 - acc: 0.9869     \n",
      "Epoch 32/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0823 - acc: 0.9893     \n",
      "Epoch 33/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0803 - acc: 0.9893     \n",
      "Epoch 34/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0785 - acc: 0.9888     \n",
      "Epoch 35/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0767 - acc: 0.9908     \n",
      "Epoch 36/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0755 - acc: 0.9898     \n",
      "Epoch 37/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0741 - acc: 0.9898     \n",
      "Epoch 38/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0725 - acc: 0.9893     \n",
      "Epoch 39/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0712 - acc: 0.9903     \n",
      "Epoch 40/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0693 - acc: 0.9908     \n",
      "Epoch 41/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0691 - acc: 0.9903     \n",
      "Epoch 42/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0669 - acc: 0.9908     \n",
      "Epoch 43/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0658 - acc: 0.9908     \n",
      "Epoch 44/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0647 - acc: 0.9903     \n",
      "Epoch 45/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0637 - acc: 0.9908     \n",
      "Epoch 46/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0626 - acc: 0.9898     \n",
      "Epoch 47/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0616 - acc: 0.9908     \n",
      "Epoch 48/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0605 - acc: 0.9908     \n",
      "Epoch 49/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0594 - acc: 0.9908     \n",
      "Epoch 50/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0583 - acc: 0.9908     - ETA: 0s - loss: 0.0539 - acc: 0.99\n",
      "Epoch 51/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0582 - acc: 0.9903     \n",
      "Epoch 52/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0567 - acc: 0.9908     \n",
      "Epoch 53/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0559 - acc: 0.9903     \n",
      "Epoch 54/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0550 - acc: 0.9908     \n",
      "Epoch 55/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0548 - acc: 0.9898     \n",
      "Epoch 56/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0535 - acc: 0.9898     \n",
      "Epoch 57/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0533 - acc: 0.9898     \n",
      "Epoch 58/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0523 - acc: 0.9898     \n",
      "Epoch 59/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0517 - acc: 0.9903     \n",
      "Epoch 60/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0507 - acc: 0.9908     \n",
      "Epoch 61/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0501 - acc: 0.9903     \n",
      "Epoch 62/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0497 - acc: 0.9903     \n",
      "Epoch 63/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0494 - acc: 0.9898     \n",
      "Epoch 64/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0489 - acc: 0.9903     \n",
      "Epoch 65/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0480 - acc: 0.9903     \n",
      "Epoch 66/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0474 - acc: 0.9903     \n",
      "Epoch 67/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0472 - acc: 0.9908     \n",
      "Epoch 68/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0469 - acc: 0.9912     \n",
      "Epoch 69/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0466 - acc: 0.9893     \n",
      "Epoch 70/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0453 - acc: 0.9908     \n",
      "Epoch 71/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0450 - acc: 0.9903     \n",
      "Epoch 72/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0446 - acc: 0.9908     \n",
      "Epoch 73/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0445 - acc: 0.9908     \n",
      "Epoch 74/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0437 - acc: 0.9908     \n",
      "Epoch 75/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0437 - acc: 0.9908     \n",
      "Epoch 76/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0433 - acc: 0.9903     \n",
      "Epoch 77/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0429 - acc: 0.9908     \n",
      "Epoch 78/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0421 - acc: 0.9908     \n",
      "Epoch 79/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0418 - acc: 0.9908     \n",
      "Epoch 80/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0415 - acc: 0.9908     \n",
      "Epoch 81/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0413 - acc: 0.9903     \n",
      "Epoch 82/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0412 - acc: 0.9908     \n",
      "Epoch 83/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0405 - acc: 0.9903     \n",
      "Epoch 84/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0405 - acc: 0.9903     \n",
      "Epoch 85/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0406 - acc: 0.9898     \n",
      "Epoch 86/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0402 - acc: 0.9903     \n",
      "Epoch 87/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0401 - acc: 0.9903     \n",
      "Epoch 88/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0392 - acc: 0.9912     \n",
      "Epoch 89/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0393 - acc: 0.9903     \n",
      "Epoch 90/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0390 - acc: 0.9903     \n",
      "Epoch 91/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0388 - acc: 0.9908     \n",
      "Epoch 92/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0385 - acc: 0.9903     \n",
      "Epoch 93/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0382 - acc: 0.9908     \n",
      "Epoch 94/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0384 - acc: 0.9893     \n",
      "Epoch 95/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0378 - acc: 0.9908     \n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 0s - loss: 0.0375 - acc: 0.9908     \n",
      "Epoch 97/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0376 - acc: 0.9912     \n",
      "Epoch 98/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0373 - acc: 0.9912     \n",
      "Epoch 99/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0370 - acc: 0.9898     \n",
      "Epoch 100/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0368 - acc: 0.9908     \n",
      " 32/228 [===>..........................] - ETA: 1sEpoch 1/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.6801 - acc: 0.8405     \n",
      "Epoch 2/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.5753 - acc: 0.8512     \n",
      "Epoch 3/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.3084 - acc: 0.9056     \n",
      "Epoch 4/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1901 - acc: 0.9538     \n",
      "Epoch 5/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1354 - acc: 0.9645     \n",
      "Epoch 6/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.1046 - acc: 0.9718     \n",
      "Epoch 7/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0879 - acc: 0.9767     \n",
      "Epoch 8/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0773 - acc: 0.9805     \n",
      "Epoch 9/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0697 - acc: 0.9815     \n",
      "Epoch 10/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0635 - acc: 0.9825     \n",
      "Epoch 11/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0579 - acc: 0.9825     \n",
      "Epoch 12/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0546 - acc: 0.9835     \n",
      "Epoch 13/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0516 - acc: 0.9839     \n",
      "Epoch 14/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0481 - acc: 0.9849     \n",
      "Epoch 15/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0462 - acc: 0.9844     \n",
      "Epoch 16/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0438 - acc: 0.9854     \n",
      "Epoch 17/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0418 - acc: 0.9869     \n",
      "Epoch 18/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0404 - acc: 0.9878     \n",
      "Epoch 19/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0380 - acc: 0.9874     \n",
      "Epoch 20/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0360 - acc: 0.9898     \n",
      "Epoch 21/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0340 - acc: 0.9898     \n",
      "Epoch 22/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0329 - acc: 0.9898     \n",
      "Epoch 23/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0319 - acc: 0.9898     \n",
      "Epoch 24/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0323 - acc: 0.9888     \n",
      "Epoch 25/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0311 - acc: 0.9903     \n",
      "Epoch 26/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0306 - acc: 0.9893     \n",
      "Epoch 27/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0293 - acc: 0.9903     \n",
      "Epoch 28/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0297 - acc: 0.9898     \n",
      "Epoch 29/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0282 - acc: 0.9893     \n",
      "Epoch 30/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0283 - acc: 0.9903     \n",
      "Epoch 31/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0268 - acc: 0.9908     \n",
      "Epoch 32/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0271 - acc: 0.9912     \n",
      "Epoch 33/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0262 - acc: 0.9922     \n",
      "Epoch 34/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0256 - acc: 0.9927     \n",
      "Epoch 35/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0258 - acc: 0.9922     \n",
      "Epoch 36/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0256 - acc: 0.9927     \n",
      "Epoch 37/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0253 - acc: 0.9937     \n",
      "Epoch 38/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0249 - acc: 0.9932     \n",
      "Epoch 39/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0255 - acc: 0.9917     \n",
      "Epoch 40/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0244 - acc: 0.9932     \n",
      "Epoch 41/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0244 - acc: 0.9922     \n",
      "Epoch 42/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0241 - acc: 0.9942     \n",
      "Epoch 43/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0239 - acc: 0.9932     \n",
      "Epoch 44/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0233 - acc: 0.9932     \n",
      "Epoch 45/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0236 - acc: 0.9927     \n",
      "Epoch 46/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0232 - acc: 0.9932     \n",
      "Epoch 47/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0230 - acc: 0.9937     \n",
      "Epoch 48/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0230 - acc: 0.9937     \n",
      "Epoch 49/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0230 - acc: 0.9927      \n",
      "Epoch 50/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0232 - acc: 0.9937      \n",
      "Epoch 51/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0228 - acc: 0.9942     \n",
      "Epoch 52/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0225 - acc: 0.9932     \n",
      "Epoch 53/100\n",
      "2056/2056 [==============================] - ETA: 0s - loss: 0.0152 - acc: 0.995 - 0s - loss: 0.0228 - acc: 0.9942     \n",
      "Epoch 54/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0233 - acc: 0.9917     \n",
      "Epoch 55/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0226 - acc: 0.9942     \n",
      "Epoch 56/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0225 - acc: 0.9932     \n",
      "Epoch 57/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0223 - acc: 0.9942     \n",
      "Epoch 58/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0223 - acc: 0.9937     \n",
      "Epoch 59/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0217 - acc: 0.9946     \n",
      "Epoch 60/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0218 - acc: 0.9937     \n",
      "Epoch 61/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0220 - acc: 0.9932     \n",
      "Epoch 62/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0219 - acc: 0.9942     \n",
      "Epoch 63/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0215 - acc: 0.9937     \n",
      "Epoch 64/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0215 - acc: 0.9946     \n",
      "Epoch 65/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0215 - acc: 0.9946     \n",
      "Epoch 66/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0224 - acc: 0.9932     \n",
      "Epoch 67/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0217 - acc: 0.9942     \n",
      "Epoch 68/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0208 - acc: 0.9937     \n",
      "Epoch 69/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0218 - acc: 0.9946     \n",
      "Epoch 70/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0214 - acc: 0.9927     \n",
      "Epoch 71/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0213 - acc: 0.9937     \n",
      "Epoch 72/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0210 - acc: 0.9937     \n",
      "Epoch 73/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0214 - acc: 0.9942     \n",
      "Epoch 74/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0209 - acc: 0.9942     \n",
      "Epoch 75/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0211 - acc: 0.9951     \n",
      "Epoch 76/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0211 - acc: 0.9942     \n",
      "Epoch 77/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0205 - acc: 0.9946     \n",
      "Epoch 78/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0209 - acc: 0.9946     \n",
      "Epoch 79/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0206 - acc: 0.9942     \n",
      "Epoch 80/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0207 - acc: 0.9946     \n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2056/2056 [==============================] - 0s - loss: 0.0205 - acc: 0.9942     \n",
      "Epoch 82/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0202 - acc: 0.9946     \n",
      "Epoch 83/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0206 - acc: 0.9932      \n",
      "Epoch 84/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0202 - acc: 0.9942     \n",
      "Epoch 85/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0207 - acc: 0.9937     \n",
      "Epoch 86/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0204 - acc: 0.9946     \n",
      "Epoch 87/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0209 - acc: 0.9937     \n",
      "Epoch 88/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0201 - acc: 0.9942     \n",
      "Epoch 89/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0203 - acc: 0.9937     \n",
      "Epoch 90/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0198 - acc: 0.9946     \n",
      "Epoch 91/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0201 - acc: 0.9937     \n",
      "Epoch 92/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0198 - acc: 0.9942     \n",
      "Epoch 93/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0198 - acc: 0.9946     \n",
      "Epoch 94/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0202 - acc: 0.9932     \n",
      "Epoch 95/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0206 - acc: 0.9932     \n",
      "Epoch 96/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0199 - acc: 0.9942      \n",
      "Epoch 97/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0198 - acc: 0.9942     \n",
      "Epoch 98/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0197 - acc: 0.9937     \n",
      "Epoch 99/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0197 - acc: 0.9942     \n",
      "Epoch 100/100\n",
      "2056/2056 [==============================] - 0s - loss: 0.0196 - acc: 0.9942     \n",
      " 32/228 [===>..........................] - ETA: 1sAccuracy mean: 0.957527005286\n",
      "Accuracy variance: 0.0141145679518\n"
     ]
    }
   ],
   "source": [
    "# estimators \n",
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential # initialize neural network library\n",
    "from keras.layers import Dense # build our layers library\n",
    "def build_classifier():\n",
    "    classifier = Sequential() # initialize neural network\n",
    "    classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = X_train.shape[1]))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()\n",
    "print(\"Accuracy mean: \"+ str(mean))\n",
    "print(\"Accuracy variance: \"+ str(variance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
